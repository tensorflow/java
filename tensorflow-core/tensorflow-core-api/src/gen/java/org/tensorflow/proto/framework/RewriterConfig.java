// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/core/protobuf/rewriter_config.proto

package org.tensorflow.proto.framework;

/**
 * <pre>
 * Graph rewriting is experimental and subject to change, not covered by any
 * API stability guarantees.
 * </pre>
 *
 * Protobuf type {@code tensorflow.RewriterConfig}
 */
public final class RewriterConfig extends
    com.google.protobuf.GeneratedMessageV3 implements
    // @@protoc_insertion_point(message_implements:tensorflow.RewriterConfig)
    RewriterConfigOrBuilder {
private static final long serialVersionUID = 0L;
  // Use RewriterConfig.newBuilder() to construct.
  private RewriterConfig(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
    super(builder);
  }
  private RewriterConfig() {
    cpuLayoutConversion_ = 0;
    layoutOptimizer_ = 0;
    constantFolding_ = 0;
    shapeOptimization_ = 0;
    remapping_ = 0;
    commonSubgraphElimination_ = 0;
    arithmeticOptimization_ = 0;
    dependencyOptimization_ = 0;
    loopOptimization_ = 0;
    functionOptimization_ = 0;
    debugStripper_ = 0;
    scopedAllocatorOptimization_ = 0;
    pinToHostOptimization_ = 0;
    implementationSelector_ = 0;
    autoMixedPrecision_ = 0;
    autoMixedPrecisionMkl_ = 0;
    autoMixedPrecisionOnednnBfloat16_ = 0;
    autoMixedPrecisionCpu_ = 0;
    usePluginOptimizers_ = 0;
    experimentalConditionalCodeMotion_ = 0;
    metaOptimizerIterations_ = 0;
    memoryOptimization_ = 0;
    memoryOptimizerTargetNodeNameScope_ = "";
    optimizers_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    customOptimizers_ = java.util.Collections.emptyList();
  }

  @java.lang.Override
  @SuppressWarnings({"unused"})
  protected java.lang.Object newInstance(
      UnusedPrivateParameter unused) {
    return new RewriterConfig();
  }

  @java.lang.Override
  public final com.google.protobuf.UnknownFieldSet
  getUnknownFields() {
    return this.unknownFields;
  }
  public static final com.google.protobuf.Descriptors.Descriptor
      getDescriptor() {
    return org.tensorflow.proto.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_descriptor;
  }

  @java.lang.Override
  protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internalGetFieldAccessorTable() {
    return org.tensorflow.proto.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_fieldAccessorTable
        .ensureFieldAccessorsInitialized(
            org.tensorflow.proto.framework.RewriterConfig.class, org.tensorflow.proto.framework.RewriterConfig.Builder.class);
  }

  /**
   * Protobuf enum {@code tensorflow.RewriterConfig.Toggle}
   */
  public enum Toggle
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DEFAULT = 0;</code>
     */
    DEFAULT(0),
    /**
     * <code>ON = 1;</code>
     */
    ON(1),
    /**
     * <code>OFF = 2;</code>
     */
    OFF(2),
    /**
     * <pre>
     * Enable some aggressive optimizations that use assumptions that TF graphs
     * may break. For example, assume the shape of a placeholder matches its
     * actual feed.
     * </pre>
     *
     * <code>AGGRESSIVE = 3;</code>
     */
    AGGRESSIVE(3),
    /**
     * <pre>
     * Run MLIR pass if there's one implemented in TFG, do nothing otherwise.
     * I.e., if there's no corresponding TFG pass, it's an OFF. This is supposed
     * to be mapped with `ON` and there's no `AGGRESSIVE` in MLIR pass now.
     * </pre>
     *
     * <code>EXPERIMENTAL_MLIR = 4;</code>
     */
    EXPERIMENTAL_MLIR(4),
    /**
     * <pre>
     * Run both MLIR and Grappler passes consecutively and MLIR pass will come
     * first.
     * </pre>
     *
     * <code>EXPERIMENTAL_BOTH = 5;</code>
     */
    EXPERIMENTAL_BOTH(5),
    UNRECOGNIZED(-1),
    ;

    /**
     * <code>DEFAULT = 0;</code>
     */
    public static final int DEFAULT_VALUE = 0;
    /**
     * <code>ON = 1;</code>
     */
    public static final int ON_VALUE = 1;
    /**
     * <code>OFF = 2;</code>
     */
    public static final int OFF_VALUE = 2;
    /**
     * <pre>
     * Enable some aggressive optimizations that use assumptions that TF graphs
     * may break. For example, assume the shape of a placeholder matches its
     * actual feed.
     * </pre>
     *
     * <code>AGGRESSIVE = 3;</code>
     */
    public static final int AGGRESSIVE_VALUE = 3;
    /**
     * <pre>
     * Run MLIR pass if there's one implemented in TFG, do nothing otherwise.
     * I.e., if there's no corresponding TFG pass, it's an OFF. This is supposed
     * to be mapped with `ON` and there's no `AGGRESSIVE` in MLIR pass now.
     * </pre>
     *
     * <code>EXPERIMENTAL_MLIR = 4;</code>
     */
    public static final int EXPERIMENTAL_MLIR_VALUE = 4;
    /**
     * <pre>
     * Run both MLIR and Grappler passes consecutively and MLIR pass will come
     * first.
     * </pre>
     *
     * <code>EXPERIMENTAL_BOTH = 5;</code>
     */
    public static final int EXPERIMENTAL_BOTH_VALUE = 5;


    public final int getNumber() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalArgumentException(
            "Can't get the number of an unknown enum value.");
      }
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static Toggle valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static Toggle forNumber(int value) {
      switch (value) {
        case 0: return DEFAULT;
        case 1: return ON;
        case 2: return OFF;
        case 3: return AGGRESSIVE;
        case 4: return EXPERIMENTAL_MLIR;
        case 5: return EXPERIMENTAL_BOTH;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<Toggle>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        Toggle> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<Toggle>() {
            public Toggle findValueByNumber(int number) {
              return Toggle.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalStateException(
            "Can't get the descriptor of an unrecognized enum value.");
      }
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.tensorflow.proto.framework.RewriterConfig.getDescriptor().getEnumTypes().get(0);
    }

    private static final Toggle[] VALUES = values();

    public static Toggle valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      if (desc.getIndex() == -1) {
        return UNRECOGNIZED;
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private Toggle(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:tensorflow.RewriterConfig.Toggle)
  }

  /**
   * <pre>
   * Enum for layout conversion between NCHW and NHWC on CPU. Default is OFF.
   * </pre>
   *
   * Protobuf enum {@code tensorflow.RewriterConfig.CpuLayout}
   */
  public enum CpuLayout
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>NO_CONVERSION_ON_CPU = 0;</code>
     */
    NO_CONVERSION_ON_CPU(0),
    /**
     * <code>NCHW_TO_NHWC = 1;</code>
     */
    NCHW_TO_NHWC(1),
    /**
     * <code>NHWC_TO_NCHW = 2;</code>
     */
    NHWC_TO_NCHW(2),
    UNRECOGNIZED(-1),
    ;

    /**
     * <code>NO_CONVERSION_ON_CPU = 0;</code>
     */
    public static final int NO_CONVERSION_ON_CPU_VALUE = 0;
    /**
     * <code>NCHW_TO_NHWC = 1;</code>
     */
    public static final int NCHW_TO_NHWC_VALUE = 1;
    /**
     * <code>NHWC_TO_NCHW = 2;</code>
     */
    public static final int NHWC_TO_NCHW_VALUE = 2;


    public final int getNumber() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalArgumentException(
            "Can't get the number of an unknown enum value.");
      }
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static CpuLayout valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static CpuLayout forNumber(int value) {
      switch (value) {
        case 0: return NO_CONVERSION_ON_CPU;
        case 1: return NCHW_TO_NHWC;
        case 2: return NHWC_TO_NCHW;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<CpuLayout>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        CpuLayout> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<CpuLayout>() {
            public CpuLayout findValueByNumber(int number) {
              return CpuLayout.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalStateException(
            "Can't get the descriptor of an unrecognized enum value.");
      }
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.tensorflow.proto.framework.RewriterConfig.getDescriptor().getEnumTypes().get(1);
    }

    private static final CpuLayout[] VALUES = values();

    public static CpuLayout valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      if (desc.getIndex() == -1) {
        return UNRECOGNIZED;
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private CpuLayout(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:tensorflow.RewriterConfig.CpuLayout)
  }

  /**
   * <pre>
   * Enum controlling the number of times to run optimizers. The default is to
   * run them twice.
   * </pre>
   *
   * Protobuf enum {@code tensorflow.RewriterConfig.NumIterationsType}
   */
  public enum NumIterationsType
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>DEFAULT_NUM_ITERS = 0;</code>
     */
    DEFAULT_NUM_ITERS(0),
    /**
     * <code>ONE = 1;</code>
     */
    ONE(1),
    /**
     * <code>TWO = 2;</code>
     */
    TWO(2),
    UNRECOGNIZED(-1),
    ;

    /**
     * <code>DEFAULT_NUM_ITERS = 0;</code>
     */
    public static final int DEFAULT_NUM_ITERS_VALUE = 0;
    /**
     * <code>ONE = 1;</code>
     */
    public static final int ONE_VALUE = 1;
    /**
     * <code>TWO = 2;</code>
     */
    public static final int TWO_VALUE = 2;


    public final int getNumber() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalArgumentException(
            "Can't get the number of an unknown enum value.");
      }
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static NumIterationsType valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static NumIterationsType forNumber(int value) {
      switch (value) {
        case 0: return DEFAULT_NUM_ITERS;
        case 1: return ONE;
        case 2: return TWO;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<NumIterationsType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        NumIterationsType> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<NumIterationsType>() {
            public NumIterationsType findValueByNumber(int number) {
              return NumIterationsType.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalStateException(
            "Can't get the descriptor of an unrecognized enum value.");
      }
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.tensorflow.proto.framework.RewriterConfig.getDescriptor().getEnumTypes().get(2);
    }

    private static final NumIterationsType[] VALUES = values();

    public static NumIterationsType valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      if (desc.getIndex() == -1) {
        return UNRECOGNIZED;
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private NumIterationsType(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:tensorflow.RewriterConfig.NumIterationsType)
  }

  /**
   * Protobuf enum {@code tensorflow.RewriterConfig.MemOptType}
   */
  public enum MemOptType
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <pre>
     * The default setting (SCHEDULING and SWAPPING HEURISTICS only)
     * </pre>
     *
     * <code>DEFAULT_MEM_OPT = 0;</code>
     */
    DEFAULT_MEM_OPT(0),
    /**
     * <pre>
     * Disabled in the meta-optimizer.
     * </pre>
     *
     * <code>NO_MEM_OPT = 1;</code>
     */
    NO_MEM_OPT(1),
    /**
     * <pre>
     * Driven by manual op-level annotations.
     * </pre>
     *
     * <code>MANUAL = 2;</code>
     */
    MANUAL(2),
    /**
     * <pre>
     * Swapping heuristic will move a tensor from the GPU to the CPU and move
     * it back when needed to reduce peak memory usage.
     * </pre>
     *
     * <code>SWAPPING_HEURISTICS = 4;</code>
     */
    SWAPPING_HEURISTICS(4),
    /**
     * <pre>
     * Recomputation heuristics will recompute ops (such as Relu activation)
     * during backprop instead of storing them, reducing peak memory usage.
     * </pre>
     *
     * <code>RECOMPUTATION_HEURISTICS = 5;</code>
     */
    RECOMPUTATION_HEURISTICS(5),
    /**
     * <pre>
     * Scheduling will split big ops such as AddN and try to enforce a schedule
     * of the new computations that decreases peak memory usage.
     * </pre>
     *
     * <code>SCHEDULING_HEURISTICS = 6;</code>
     */
    SCHEDULING_HEURISTICS(6),
    /**
     * <pre>
     * Use any combination of swapping and recomputation heuristics.
     * </pre>
     *
     * <code>HEURISTICS = 3;</code>
     */
    HEURISTICS(3),
    UNRECOGNIZED(-1),
    ;

    /**
     * <pre>
     * The default setting (SCHEDULING and SWAPPING HEURISTICS only)
     * </pre>
     *
     * <code>DEFAULT_MEM_OPT = 0;</code>
     */
    public static final int DEFAULT_MEM_OPT_VALUE = 0;
    /**
     * <pre>
     * Disabled in the meta-optimizer.
     * </pre>
     *
     * <code>NO_MEM_OPT = 1;</code>
     */
    public static final int NO_MEM_OPT_VALUE = 1;
    /**
     * <pre>
     * Driven by manual op-level annotations.
     * </pre>
     *
     * <code>MANUAL = 2;</code>
     */
    public static final int MANUAL_VALUE = 2;
    /**
     * <pre>
     * Swapping heuristic will move a tensor from the GPU to the CPU and move
     * it back when needed to reduce peak memory usage.
     * </pre>
     *
     * <code>SWAPPING_HEURISTICS = 4;</code>
     */
    public static final int SWAPPING_HEURISTICS_VALUE = 4;
    /**
     * <pre>
     * Recomputation heuristics will recompute ops (such as Relu activation)
     * during backprop instead of storing them, reducing peak memory usage.
     * </pre>
     *
     * <code>RECOMPUTATION_HEURISTICS = 5;</code>
     */
    public static final int RECOMPUTATION_HEURISTICS_VALUE = 5;
    /**
     * <pre>
     * Scheduling will split big ops such as AddN and try to enforce a schedule
     * of the new computations that decreases peak memory usage.
     * </pre>
     *
     * <code>SCHEDULING_HEURISTICS = 6;</code>
     */
    public static final int SCHEDULING_HEURISTICS_VALUE = 6;
    /**
     * <pre>
     * Use any combination of swapping and recomputation heuristics.
     * </pre>
     *
     * <code>HEURISTICS = 3;</code>
     */
    public static final int HEURISTICS_VALUE = 3;


    public final int getNumber() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalArgumentException(
            "Can't get the number of an unknown enum value.");
      }
      return value;
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static MemOptType valueOf(int value) {
      return forNumber(value);
    }

    /**
     * @param value The numeric wire value of the corresponding enum entry.
     * @return The enum associated with the given numeric wire value.
     */
    public static MemOptType forNumber(int value) {
      switch (value) {
        case 0: return DEFAULT_MEM_OPT;
        case 1: return NO_MEM_OPT;
        case 2: return MANUAL;
        case 4: return SWAPPING_HEURISTICS;
        case 5: return RECOMPUTATION_HEURISTICS;
        case 6: return SCHEDULING_HEURISTICS;
        case 3: return HEURISTICS;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<MemOptType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        MemOptType> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<MemOptType>() {
            public MemOptType findValueByNumber(int number) {
              return MemOptType.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalStateException(
            "Can't get the descriptor of an unrecognized enum value.");
      }
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.tensorflow.proto.framework.RewriterConfig.getDescriptor().getEnumTypes().get(3);
    }

    private static final MemOptType[] VALUES = values();

    public static MemOptType valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      if (desc.getIndex() == -1) {
        return UNRECOGNIZED;
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private MemOptType(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:tensorflow.RewriterConfig.MemOptType)
  }

  public interface CustomGraphOptimizerOrBuilder extends
      // @@protoc_insertion_point(interface_extends:tensorflow.RewriterConfig.CustomGraphOptimizer)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>string name = 1;</code>
     * @return The name.
     */
    java.lang.String getName();
    /**
     * <code>string name = 1;</code>
     * @return The bytes for name.
     */
    com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <code>map&lt;string, .tensorflow.AttrValue&gt; parameter_map = 2;</code>
     */
    int getParameterMapCount();
    /**
     * <code>map&lt;string, .tensorflow.AttrValue&gt; parameter_map = 2;</code>
     */
    boolean containsParameterMap(
        java.lang.String key);
    /**
     * Use {@link #getParameterMapMap()} instead.
     */
    @java.lang.Deprecated
    java.util.Map<java.lang.String, org.tensorflow.proto.framework.AttrValue>
    getParameterMap();
    /**
     * <code>map&lt;string, .tensorflow.AttrValue&gt; parameter_map = 2;</code>
     */
    java.util.Map<java.lang.String, org.tensorflow.proto.framework.AttrValue>
    getParameterMapMap();
    /**
     * <code>map&lt;string, .tensorflow.AttrValue&gt; parameter_map = 2;</code>
     */

    /* nullable */
org.tensorflow.proto.framework.AttrValue getParameterMapOrDefault(
        java.lang.String key,
        /* nullable */
org.tensorflow.proto.framework.AttrValue defaultValue);
    /**
     * <code>map&lt;string, .tensorflow.AttrValue&gt; parameter_map = 2;</code>
     */

    org.tensorflow.proto.framework.AttrValue getParameterMapOrThrow(
        java.lang.String key);
  }
  /**
   * <pre>
   * Message to describe custom graph optimizer and its parameters
   * </pre>
   *
   * Protobuf type {@code tensorflow.RewriterConfig.CustomGraphOptimizer}
   */
  public static final class CustomGraphOptimizer extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:tensorflow.RewriterConfig.CustomGraphOptimizer)
      CustomGraphOptimizerOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use CustomGraphOptimizer.newBuilder() to construct.
    private CustomGraphOptimizer(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private CustomGraphOptimizer() {
      name_ = "";
    }

    @java.lang.Override
    @SuppressWarnings({"unused"})
    protected java.lang.Object newInstance(
        UnusedPrivateParameter unused) {
      return new CustomGraphOptimizer();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.tensorflow.proto.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_CustomGraphOptimizer_descriptor;
    }

    @SuppressWarnings({"rawtypes"})
    @java.lang.Override
    protected com.google.protobuf.MapField internalGetMapField(
        int number) {
      switch (number) {
        case 2:
          return internalGetParameterMap();
        default:
          throw new RuntimeException(
              "Invalid map field number: " + number);
      }
    }
    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.tensorflow.proto.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_CustomGraphOptimizer_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.class, org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.Builder.class);
    }

    public static final int NAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object name_;
    /**
     * <code>string name = 1;</code>
     * @return The name.
     */
    @java.lang.Override
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        name_ = s;
        return s;
      }
    }
    /**
     * <code>string name = 1;</code>
     * @return The bytes for name.
     */
    @java.lang.Override
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int PARAMETER_MAP_FIELD_NUMBER = 2;
    private static final class ParameterMapDefaultEntryHolder {
      static final com.google.protobuf.MapEntry<
          java.lang.String, org.tensorflow.proto.framework.AttrValue> defaultEntry =
              com.google.protobuf.MapEntry
              .<java.lang.String, org.tensorflow.proto.framework.AttrValue>newDefaultInstance(
                  org.tensorflow.proto.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_CustomGraphOptimizer_ParameterMapEntry_descriptor, 
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "",
                  com.google.protobuf.WireFormat.FieldType.MESSAGE,
                  org.tensorflow.proto.framework.AttrValue.getDefaultInstance());
    }
    private com.google.protobuf.MapField<
        java.lang.String, org.tensorflow.proto.framework.AttrValue> parameterMap_;
    private com.google.protobuf.MapField<java.lang.String, org.tensorflow.proto.framework.AttrValue>
    internalGetParameterMap() {
      if (parameterMap_ == null) {
        return com.google.protobuf.MapField.emptyMapField(
            ParameterMapDefaultEntryHolder.defaultEntry);
      }
      return parameterMap_;
    }

    public int getParameterMapCount() {
      return internalGetParameterMap().getMap().size();
    }
    /**
     * <code>map&lt;string, .tensorflow.AttrValue&gt; parameter_map = 2;</code>
     */

    @java.lang.Override
    public boolean containsParameterMap(
        java.lang.String key) {
      if (key == null) { throw new NullPointerException("map key"); }
      return internalGetParameterMap().getMap().containsKey(key);
    }
    /**
     * Use {@link #getParameterMapMap()} instead.
     */
    @java.lang.Override
    @java.lang.Deprecated
    public java.util.Map<java.lang.String, org.tensorflow.proto.framework.AttrValue> getParameterMap() {
      return getParameterMapMap();
    }
    /**
     * <code>map&lt;string, .tensorflow.AttrValue&gt; parameter_map = 2;</code>
     */
    @java.lang.Override

    public java.util.Map<java.lang.String, org.tensorflow.proto.framework.AttrValue> getParameterMapMap() {
      return internalGetParameterMap().getMap();
    }
    /**
     * <code>map&lt;string, .tensorflow.AttrValue&gt; parameter_map = 2;</code>
     */
    @java.lang.Override

    public org.tensorflow.proto.framework.AttrValue getParameterMapOrDefault(
        java.lang.String key,
        org.tensorflow.proto.framework.AttrValue defaultValue) {
      if (key == null) { throw new NullPointerException("map key"); }
      java.util.Map<java.lang.String, org.tensorflow.proto.framework.AttrValue> map =
          internalGetParameterMap().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     * <code>map&lt;string, .tensorflow.AttrValue&gt; parameter_map = 2;</code>
     */
    @java.lang.Override

    public org.tensorflow.proto.framework.AttrValue getParameterMapOrThrow(
        java.lang.String key) {
      if (key == null) { throw new NullPointerException("map key"); }
      java.util.Map<java.lang.String, org.tensorflow.proto.framework.AttrValue> map =
          internalGetParameterMap().getMap();
      if (!map.containsKey(key)) {
        throw new java.lang.IllegalArgumentException();
      }
      return map.get(key);
    }

    private byte memoizedIsInitialized = -1;
    @java.lang.Override
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    @java.lang.Override
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(name_)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
      }
      com.google.protobuf.GeneratedMessageV3
        .serializeStringMapTo(
          output,
          internalGetParameterMap(),
          ParameterMapDefaultEntryHolder.defaultEntry,
          2);
      getUnknownFields().writeTo(output);
    }

    @java.lang.Override
    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(name_)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
      }
      for (java.util.Map.Entry<java.lang.String, org.tensorflow.proto.framework.AttrValue> entry
           : internalGetParameterMap().getMap().entrySet()) {
        com.google.protobuf.MapEntry<java.lang.String, org.tensorflow.proto.framework.AttrValue>
        parameterMap__ = ParameterMapDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(2, parameterMap__);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer)) {
        return super.equals(obj);
      }
      org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer other = (org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer) obj;

      if (!getName()
          .equals(other.getName())) return false;
      if (!internalGetParameterMap().equals(
          other.internalGetParameterMap())) return false;
      if (!getUnknownFields().equals(other.getUnknownFields())) return false;
      return true;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      hash = (37 * hash) + NAME_FIELD_NUMBER;
      hash = (53 * hash) + getName().hashCode();
      if (!internalGetParameterMap().getMap().isEmpty()) {
        hash = (37 * hash) + PARAMETER_MAP_FIELD_NUMBER;
        hash = (53 * hash) + internalGetParameterMap().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    @java.lang.Override
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    @java.lang.Override
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Message to describe custom graph optimizer and its parameters
     * </pre>
     *
     * Protobuf type {@code tensorflow.RewriterConfig.CustomGraphOptimizer}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:tensorflow.RewriterConfig.CustomGraphOptimizer)
        org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizerOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.tensorflow.proto.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_CustomGraphOptimizer_descriptor;
      }

      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMapField(
          int number) {
        switch (number) {
          case 2:
            return internalGetParameterMap();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMutableMapField(
          int number) {
        switch (number) {
          case 2:
            return internalGetMutableParameterMap();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @java.lang.Override
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.tensorflow.proto.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_CustomGraphOptimizer_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.class, org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.Builder.class);
      }

      // Construct using org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.newBuilder()
      private Builder() {

      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);

      }
      @java.lang.Override
      public Builder clear() {
        super.clear();
        name_ = "";

        internalGetMutableParameterMap().clear();
        return this;
      }

      @java.lang.Override
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.tensorflow.proto.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_CustomGraphOptimizer_descriptor;
      }

      @java.lang.Override
      public org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer getDefaultInstanceForType() {
        return org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.getDefaultInstance();
      }

      @java.lang.Override
      public org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer build() {
        org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      @java.lang.Override
      public org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer buildPartial() {
        org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer result = new org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer(this);
        int from_bitField0_ = bitField0_;
        result.name_ = name_;
        result.parameterMap_ = internalGetParameterMap();
        result.parameterMap_.makeImmutable();
        onBuilt();
        return result;
      }

      @java.lang.Override
      public Builder clone() {
        return super.clone();
      }
      @java.lang.Override
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.setField(field, value);
      }
      @java.lang.Override
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return super.clearField(field);
      }
      @java.lang.Override
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return super.clearOneof(oneof);
      }
      @java.lang.Override
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return super.setRepeatedField(field, index, value);
      }
      @java.lang.Override
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return super.addRepeatedField(field, value);
      }
      @java.lang.Override
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer) {
          return mergeFrom((org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer other) {
        if (other == org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.getDefaultInstance()) return this;
        if (!other.getName().isEmpty()) {
          name_ = other.name_;
          onChanged();
        }
        internalGetMutableParameterMap().mergeFrom(
            other.internalGetParameterMap());
        this.mergeUnknownFields(other.getUnknownFields());
        onChanged();
        return this;
      }

      @java.lang.Override
      public final boolean isInitialized() {
        return true;
      }

      @java.lang.Override
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        if (extensionRegistry == null) {
          throw new java.lang.NullPointerException();
        }
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              case 10: {
                name_ = input.readStringRequireUtf8();

                break;
              } // case 10
              case 18: {
                com.google.protobuf.MapEntry<java.lang.String, org.tensorflow.proto.framework.AttrValue>
                parameterMap__ = input.readMessage(
                    ParameterMapDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
                internalGetMutableParameterMap().getMutableMap().put(
                    parameterMap__.getKey(), parameterMap__.getValue());
                break;
              } // case 18
              default: {
                if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                  done = true; // was an endgroup tag
                }
                break;
              } // default:
            } // switch (tag)
          } // while (!done)
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.unwrapIOException();
        } finally {
          onChanged();
        } // finally
        return this;
      }
      private int bitField0_;

      private java.lang.Object name_ = "";
      /**
       * <code>string name = 1;</code>
       * @return The name.
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>string name = 1;</code>
       * @return The bytes for name.
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>string name = 1;</code>
       * @param value The name to set.
       * @return This builder for chaining.
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>string name = 1;</code>
       * @return This builder for chaining.
       */
      public Builder clearName() {
        
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <code>string name = 1;</code>
       * @param value The bytes for name to set.
       * @return This builder for chaining.
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        name_ = value;
        onChanged();
        return this;
      }

      private com.google.protobuf.MapField<
          java.lang.String, org.tensorflow.proto.framework.AttrValue> parameterMap_;
      private com.google.protobuf.MapField<java.lang.String, org.tensorflow.proto.framework.AttrValue>
      internalGetParameterMap() {
        if (parameterMap_ == null) {
          return com.google.protobuf.MapField.emptyMapField(
              ParameterMapDefaultEntryHolder.defaultEntry);
        }
        return parameterMap_;
      }
      private com.google.protobuf.MapField<java.lang.String, org.tensorflow.proto.framework.AttrValue>
      internalGetMutableParameterMap() {
        onChanged();;
        if (parameterMap_ == null) {
          parameterMap_ = com.google.protobuf.MapField.newMapField(
              ParameterMapDefaultEntryHolder.defaultEntry);
        }
        if (!parameterMap_.isMutable()) {
          parameterMap_ = parameterMap_.copy();
        }
        return parameterMap_;
      }

      public int getParameterMapCount() {
        return internalGetParameterMap().getMap().size();
      }
      /**
       * <code>map&lt;string, .tensorflow.AttrValue&gt; parameter_map = 2;</code>
       */

      @java.lang.Override
      public boolean containsParameterMap(
          java.lang.String key) {
        if (key == null) { throw new NullPointerException("map key"); }
        return internalGetParameterMap().getMap().containsKey(key);
      }
      /**
       * Use {@link #getParameterMapMap()} instead.
       */
      @java.lang.Override
      @java.lang.Deprecated
      public java.util.Map<java.lang.String, org.tensorflow.proto.framework.AttrValue> getParameterMap() {
        return getParameterMapMap();
      }
      /**
       * <code>map&lt;string, .tensorflow.AttrValue&gt; parameter_map = 2;</code>
       */
      @java.lang.Override

      public java.util.Map<java.lang.String, org.tensorflow.proto.framework.AttrValue> getParameterMapMap() {
        return internalGetParameterMap().getMap();
      }
      /**
       * <code>map&lt;string, .tensorflow.AttrValue&gt; parameter_map = 2;</code>
       */
      @java.lang.Override

      public org.tensorflow.proto.framework.AttrValue getParameterMapOrDefault(
          java.lang.String key,
          org.tensorflow.proto.framework.AttrValue defaultValue) {
        if (key == null) { throw new NullPointerException("map key"); }
        java.util.Map<java.lang.String, org.tensorflow.proto.framework.AttrValue> map =
            internalGetParameterMap().getMap();
        return map.containsKey(key) ? map.get(key) : defaultValue;
      }
      /**
       * <code>map&lt;string, .tensorflow.AttrValue&gt; parameter_map = 2;</code>
       */
      @java.lang.Override

      public org.tensorflow.proto.framework.AttrValue getParameterMapOrThrow(
          java.lang.String key) {
        if (key == null) { throw new NullPointerException("map key"); }
        java.util.Map<java.lang.String, org.tensorflow.proto.framework.AttrValue> map =
            internalGetParameterMap().getMap();
        if (!map.containsKey(key)) {
          throw new java.lang.IllegalArgumentException();
        }
        return map.get(key);
      }

      public Builder clearParameterMap() {
        internalGetMutableParameterMap().getMutableMap()
            .clear();
        return this;
      }
      /**
       * <code>map&lt;string, .tensorflow.AttrValue&gt; parameter_map = 2;</code>
       */

      public Builder removeParameterMap(
          java.lang.String key) {
        if (key == null) { throw new NullPointerException("map key"); }
        internalGetMutableParameterMap().getMutableMap()
            .remove(key);
        return this;
      }
      /**
       * Use alternate mutation accessors instead.
       */
      @java.lang.Deprecated
      public java.util.Map<java.lang.String, org.tensorflow.proto.framework.AttrValue>
      getMutableParameterMap() {
        return internalGetMutableParameterMap().getMutableMap();
      }
      /**
       * <code>map&lt;string, .tensorflow.AttrValue&gt; parameter_map = 2;</code>
       */
      public Builder putParameterMap(
          java.lang.String key,
          org.tensorflow.proto.framework.AttrValue value) {
        if (key == null) { throw new NullPointerException("map key"); }
        if (value == null) {
  throw new NullPointerException("map value");
}

        internalGetMutableParameterMap().getMutableMap()
            .put(key, value);
        return this;
      }
      /**
       * <code>map&lt;string, .tensorflow.AttrValue&gt; parameter_map = 2;</code>
       */

      public Builder putAllParameterMap(
          java.util.Map<java.lang.String, org.tensorflow.proto.framework.AttrValue> values) {
        internalGetMutableParameterMap().getMutableMap()
            .putAll(values);
        return this;
      }
      @java.lang.Override
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      @java.lang.Override
      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:tensorflow.RewriterConfig.CustomGraphOptimizer)
    }

    // @@protoc_insertion_point(class_scope:tensorflow.RewriterConfig.CustomGraphOptimizer)
    private static final org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer();
    }

    public static org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<CustomGraphOptimizer>
        PARSER = new com.google.protobuf.AbstractParser<CustomGraphOptimizer>() {
      @java.lang.Override
      public CustomGraphOptimizer parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        Builder builder = newBuilder();
        try {
          builder.mergeFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(builder.buildPartial());
        } catch (com.google.protobuf.UninitializedMessageException e) {
          throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(e)
              .setUnfinishedMessage(builder.buildPartial());
        }
        return builder.buildPartial();
      }
    };

    public static com.google.protobuf.Parser<CustomGraphOptimizer> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<CustomGraphOptimizer> getParserForType() {
      return PARSER;
    }

    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public static final int CPU_LAYOUT_CONVERSION_FIELD_NUMBER = 50;
  private int cpuLayoutConversion_;
  /**
   * <pre>
   * CPU Conversion settings between NHCW and NCHW.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.CpuLayout cpu_layout_conversion = 50;</code>
   * @return The enum numeric value on the wire for cpuLayoutConversion.
   */
  @java.lang.Override public int getCpuLayoutConversionValue() {
    return cpuLayoutConversion_;
  }
  /**
   * <pre>
   * CPU Conversion settings between NHCW and NCHW.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.CpuLayout cpu_layout_conversion = 50;</code>
   * @return The cpuLayoutConversion.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.CpuLayout getCpuLayoutConversion() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.CpuLayout result = org.tensorflow.proto.framework.RewriterConfig.CpuLayout.valueOf(cpuLayoutConversion_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.CpuLayout.UNRECOGNIZED : result;
  }

  public static final int LAYOUT_OPTIMIZER_FIELD_NUMBER = 1;
  private int layoutOptimizer_;
  /**
   * <pre>
   * Optimize tensor layouts (default is ON)
   * e.g. This will try to use NCHW layout on GPU which is faster.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle layout_optimizer = 1;</code>
   * @return The enum numeric value on the wire for layoutOptimizer.
   */
  @java.lang.Override public int getLayoutOptimizerValue() {
    return layoutOptimizer_;
  }
  /**
   * <pre>
   * Optimize tensor layouts (default is ON)
   * e.g. This will try to use NCHW layout on GPU which is faster.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle layout_optimizer = 1;</code>
   * @return The layoutOptimizer.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.Toggle getLayoutOptimizer() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(layoutOptimizer_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int CONSTANT_FOLDING_FIELD_NUMBER = 3;
  private int constantFolding_;
  /**
   * <pre>
   * Fold constants (default is ON)
   * Statically infer the value of tensors when possible, and materialize the
   * result using constants.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
   * @return The enum numeric value on the wire for constantFolding.
   */
  @java.lang.Override public int getConstantFoldingValue() {
    return constantFolding_;
  }
  /**
   * <pre>
   * Fold constants (default is ON)
   * Statically infer the value of tensors when possible, and materialize the
   * result using constants.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
   * @return The constantFolding.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.Toggle getConstantFolding() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(constantFolding_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int SHAPE_OPTIMIZATION_FIELD_NUMBER = 13;
  private int shapeOptimization_;
  /**
   * <pre>
   * Shape optimizations (default is ON)
   * Simplify computations made on shapes.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle shape_optimization = 13;</code>
   * @return The enum numeric value on the wire for shapeOptimization.
   */
  @java.lang.Override public int getShapeOptimizationValue() {
    return shapeOptimization_;
  }
  /**
   * <pre>
   * Shape optimizations (default is ON)
   * Simplify computations made on shapes.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle shape_optimization = 13;</code>
   * @return The shapeOptimization.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.Toggle getShapeOptimization() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(shapeOptimization_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int REMAPPING_FIELD_NUMBER = 14;
  private int remapping_;
  /**
   * <pre>
   * Remapping (default is ON)
   * Remap subgraphs onto more efficient implementations.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle remapping = 14;</code>
   * @return The enum numeric value on the wire for remapping.
   */
  @java.lang.Override public int getRemappingValue() {
    return remapping_;
  }
  /**
   * <pre>
   * Remapping (default is ON)
   * Remap subgraphs onto more efficient implementations.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle remapping = 14;</code>
   * @return The remapping.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.Toggle getRemapping() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(remapping_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int COMMON_SUBGRAPH_ELIMINATION_FIELD_NUMBER = 24;
  private int commonSubgraphElimination_;
  /**
   * <pre>
   * Common subgraph elimination (default is ON)
   * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle common_subgraph_elimination = 24;</code>
   * @return The enum numeric value on the wire for commonSubgraphElimination.
   */
  @java.lang.Override public int getCommonSubgraphEliminationValue() {
    return commonSubgraphElimination_;
  }
  /**
   * <pre>
   * Common subgraph elimination (default is ON)
   * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle common_subgraph_elimination = 24;</code>
   * @return The commonSubgraphElimination.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.Toggle getCommonSubgraphElimination() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(commonSubgraphElimination_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int ARITHMETIC_OPTIMIZATION_FIELD_NUMBER = 7;
  private int arithmeticOptimization_;
  /**
   * <pre>
   * Arithmetic optimizations (default is ON)
   * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
   * @return The enum numeric value on the wire for arithmeticOptimization.
   */
  @java.lang.Override public int getArithmeticOptimizationValue() {
    return arithmeticOptimization_;
  }
  /**
   * <pre>
   * Arithmetic optimizations (default is ON)
   * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
   * @return The arithmeticOptimization.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.Toggle getArithmeticOptimization() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(arithmeticOptimization_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int DEPENDENCY_OPTIMIZATION_FIELD_NUMBER = 8;
  private int dependencyOptimization_;
  /**
   * <pre>
   * Control dependency optimizations (default is ON).
   * Remove redundant control dependencies, which may enable other optimization.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle dependency_optimization = 8;</code>
   * @return The enum numeric value on the wire for dependencyOptimization.
   */
  @java.lang.Override public int getDependencyOptimizationValue() {
    return dependencyOptimization_;
  }
  /**
   * <pre>
   * Control dependency optimizations (default is ON).
   * Remove redundant control dependencies, which may enable other optimization.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle dependency_optimization = 8;</code>
   * @return The dependencyOptimization.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.Toggle getDependencyOptimization() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(dependencyOptimization_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int LOOP_OPTIMIZATION_FIELD_NUMBER = 9;
  private int loopOptimization_;
  /**
   * <pre>
   * Loop optimizations (default is ON).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle loop_optimization = 9;</code>
   * @return The enum numeric value on the wire for loopOptimization.
   */
  @java.lang.Override public int getLoopOptimizationValue() {
    return loopOptimization_;
  }
  /**
   * <pre>
   * Loop optimizations (default is ON).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle loop_optimization = 9;</code>
   * @return The loopOptimization.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.Toggle getLoopOptimization() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(loopOptimization_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int FUNCTION_OPTIMIZATION_FIELD_NUMBER = 10;
  private int functionOptimization_;
  /**
   * <pre>
   * Function optimizations (default is ON).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle function_optimization = 10;</code>
   * @return The enum numeric value on the wire for functionOptimization.
   */
  @java.lang.Override public int getFunctionOptimizationValue() {
    return functionOptimization_;
  }
  /**
   * <pre>
   * Function optimizations (default is ON).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle function_optimization = 10;</code>
   * @return The functionOptimization.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.Toggle getFunctionOptimization() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(functionOptimization_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int DEBUG_STRIPPER_FIELD_NUMBER = 11;
  private int debugStripper_;
  /**
   * <pre>
   * Strips debug-related nodes from the graph (off by default).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle debug_stripper = 11;</code>
   * @return The enum numeric value on the wire for debugStripper.
   */
  @java.lang.Override public int getDebugStripperValue() {
    return debugStripper_;
  }
  /**
   * <pre>
   * Strips debug-related nodes from the graph (off by default).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle debug_stripper = 11;</code>
   * @return The debugStripper.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.Toggle getDebugStripper() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(debugStripper_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int DISABLE_MODEL_PRUNING_FIELD_NUMBER = 2;
  private boolean disableModelPruning_;
  /**
   * <pre>
   * If true, don't remove unnecessary ops from the graph
   * </pre>
   *
   * <code>bool disable_model_pruning = 2;</code>
   * @return The disableModelPruning.
   */
  @java.lang.Override
  public boolean getDisableModelPruning() {
    return disableModelPruning_;
  }

  public static final int SCOPED_ALLOCATOR_OPTIMIZATION_FIELD_NUMBER = 15;
  private int scopedAllocatorOptimization_;
  /**
   * <pre>
   * Try to allocate some independent Op outputs contiguously in order to
   * merge or eliminate downstream Ops (off by default).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle scoped_allocator_optimization = 15;</code>
   * @return The enum numeric value on the wire for scopedAllocatorOptimization.
   */
  @java.lang.Override public int getScopedAllocatorOptimizationValue() {
    return scopedAllocatorOptimization_;
  }
  /**
   * <pre>
   * Try to allocate some independent Op outputs contiguously in order to
   * merge or eliminate downstream Ops (off by default).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle scoped_allocator_optimization = 15;</code>
   * @return The scopedAllocatorOptimization.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.Toggle getScopedAllocatorOptimization() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(scopedAllocatorOptimization_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int PIN_TO_HOST_OPTIMIZATION_FIELD_NUMBER = 18;
  private int pinToHostOptimization_;
  /**
   * <pre>
   * Force small ops onto the CPU (default is OFF).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle pin_to_host_optimization = 18;</code>
   * @return The enum numeric value on the wire for pinToHostOptimization.
   */
  @java.lang.Override public int getPinToHostOptimizationValue() {
    return pinToHostOptimization_;
  }
  /**
   * <pre>
   * Force small ops onto the CPU (default is OFF).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle pin_to_host_optimization = 18;</code>
   * @return The pinToHostOptimization.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.Toggle getPinToHostOptimization() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(pinToHostOptimization_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int IMPLEMENTATION_SELECTOR_FIELD_NUMBER = 22;
  private int implementationSelector_;
  /**
   * <pre>
   * Enable the swap of kernel implementations based on the device placement
   * (default is ON).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle implementation_selector = 22;</code>
   * @return The enum numeric value on the wire for implementationSelector.
   */
  @java.lang.Override public int getImplementationSelectorValue() {
    return implementationSelector_;
  }
  /**
   * <pre>
   * Enable the swap of kernel implementations based on the device placement
   * (default is ON).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle implementation_selector = 22;</code>
   * @return The implementationSelector.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.Toggle getImplementationSelector() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(implementationSelector_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int AUTO_MIXED_PRECISION_FIELD_NUMBER = 23;
  private int autoMixedPrecision_;
  /**
   * <pre>
   * Optimize data types for CUDA (default is OFF).
   * This will try to use float16 on GPU which is faster.
   * Note that this can change the numerical stability of the graph and may
   * require the use of loss scaling to maintain model convergence.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision = 23;</code>
   * @return The enum numeric value on the wire for autoMixedPrecision.
   */
  @java.lang.Override public int getAutoMixedPrecisionValue() {
    return autoMixedPrecision_;
  }
  /**
   * <pre>
   * Optimize data types for CUDA (default is OFF).
   * This will try to use float16 on GPU which is faster.
   * Note that this can change the numerical stability of the graph and may
   * require the use of loss scaling to maintain model convergence.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision = 23;</code>
   * @return The autoMixedPrecision.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.Toggle getAutoMixedPrecision() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(autoMixedPrecision_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int AUTO_MIXED_PRECISION_MKL_FIELD_NUMBER = 25;
  private int autoMixedPrecisionMkl_;
  /**
   * <pre>
   * Optimize data types for oneDNN (default is OFF).
   * This will try to use bfloat16 on CPUs, which is faster.
   * Note that this can change the numerical stability of the graph.
   * Note: this is deprecated.
   * It is replaced by auto_mixed_precision_onednn_bfloat16
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_mkl = 25;</code>
   * @return The enum numeric value on the wire for autoMixedPrecisionMkl.
   */
  @java.lang.Override public int getAutoMixedPrecisionMklValue() {
    return autoMixedPrecisionMkl_;
  }
  /**
   * <pre>
   * Optimize data types for oneDNN (default is OFF).
   * This will try to use bfloat16 on CPUs, which is faster.
   * Note that this can change the numerical stability of the graph.
   * Note: this is deprecated.
   * It is replaced by auto_mixed_precision_onednn_bfloat16
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_mkl = 25;</code>
   * @return The autoMixedPrecisionMkl.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.Toggle getAutoMixedPrecisionMkl() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(autoMixedPrecisionMkl_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int AUTO_MIXED_PRECISION_ONEDNN_BFLOAT16_FIELD_NUMBER = 31;
  private int autoMixedPrecisionOnednnBfloat16_;
  /**
   * <pre>
   * Optimize data types for oneDNN (default is OFF).
   * This will try to use bfloat16 on CPUs, which is faster.
   * Note that this can change the numerical stability of the graph.
   * Note: this is equivalent to the deprecated option auto_mixed_precision_mkl
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_onednn_bfloat16 = 31;</code>
   * @return The enum numeric value on the wire for autoMixedPrecisionOnednnBfloat16.
   */
  @java.lang.Override public int getAutoMixedPrecisionOnednnBfloat16Value() {
    return autoMixedPrecisionOnednnBfloat16_;
  }
  /**
   * <pre>
   * Optimize data types for oneDNN (default is OFF).
   * This will try to use bfloat16 on CPUs, which is faster.
   * Note that this can change the numerical stability of the graph.
   * Note: this is equivalent to the deprecated option auto_mixed_precision_mkl
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_onednn_bfloat16 = 31;</code>
   * @return The autoMixedPrecisionOnednnBfloat16.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.Toggle getAutoMixedPrecisionOnednnBfloat16() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(autoMixedPrecisionOnednnBfloat16_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int AUTO_MIXED_PRECISION_CPU_FIELD_NUMBER = 29;
  private int autoMixedPrecisionCpu_;
  /**
   * <pre>
   * Emulate a model using data type float16 on CPU (default is OFF).
   * This will try to emulate the float16 inputs and outputs of an operator
   * on CPU to have better correlation with float16 on GPU; however the
   * computation in the operator is based on float32.
   * Note that this can change the numerical stability of the graph.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_cpu = 29;</code>
   * @return The enum numeric value on the wire for autoMixedPrecisionCpu.
   */
  @java.lang.Override public int getAutoMixedPrecisionCpuValue() {
    return autoMixedPrecisionCpu_;
  }
  /**
   * <pre>
   * Emulate a model using data type float16 on CPU (default is OFF).
   * This will try to emulate the float16 inputs and outputs of an operator
   * on CPU to have better correlation with float16 on GPU; however the
   * computation in the operator is based on float32.
   * Note that this can change the numerical stability of the graph.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_cpu = 29;</code>
   * @return The autoMixedPrecisionCpu.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.Toggle getAutoMixedPrecisionCpu() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(autoMixedPrecisionCpu_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int DISABLE_META_OPTIMIZER_FIELD_NUMBER = 19;
  private boolean disableMetaOptimizer_;
  /**
   * <pre>
   * Disable the entire meta optimizer (off by default).
   * </pre>
   *
   * <code>bool disable_meta_optimizer = 19;</code>
   * @return The disableMetaOptimizer.
   */
  @java.lang.Override
  public boolean getDisableMetaOptimizer() {
    return disableMetaOptimizer_;
  }

  public static final int USE_PLUGIN_OPTIMIZERS_FIELD_NUMBER = 28;
  private int usePluginOptimizers_;
  /**
   * <pre>
   * Optimizers registered by plugin (default is ON)
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle use_plugin_optimizers = 28;</code>
   * @return The enum numeric value on the wire for usePluginOptimizers.
   */
  @java.lang.Override public int getUsePluginOptimizersValue() {
    return usePluginOptimizers_;
  }
  /**
   * <pre>
   * Optimizers registered by plugin (default is ON)
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle use_plugin_optimizers = 28;</code>
   * @return The usePluginOptimizers.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.Toggle getUsePluginOptimizers() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(usePluginOptimizers_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int EXPERIMENTAL_CONDITIONAL_CODE_MOTION_FIELD_NUMBER = 30;
  private int experimentalConditionalCodeMotion_;
  /**
   * <pre>
   * Conditional code motion (default is ON).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle experimental_conditional_code_motion = 30;</code>
   * @return The enum numeric value on the wire for experimentalConditionalCodeMotion.
   */
  @java.lang.Override public int getExperimentalConditionalCodeMotionValue() {
    return experimentalConditionalCodeMotion_;
  }
  /**
   * <pre>
   * Conditional code motion (default is ON).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.Toggle experimental_conditional_code_motion = 30;</code>
   * @return The experimentalConditionalCodeMotion.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.Toggle getExperimentalConditionalCodeMotion() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(experimentalConditionalCodeMotion_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
  }

  public static final int META_OPTIMIZER_ITERATIONS_FIELD_NUMBER = 12;
  private int metaOptimizerIterations_;
  /**
   * <pre>
   * Controls how many times we run the optimizers in meta optimizer (default
   * is once).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;</code>
   * @return The enum numeric value on the wire for metaOptimizerIterations.
   */
  @java.lang.Override public int getMetaOptimizerIterationsValue() {
    return metaOptimizerIterations_;
  }
  /**
   * <pre>
   * Controls how many times we run the optimizers in meta optimizer (default
   * is once).
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;</code>
   * @return The metaOptimizerIterations.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.NumIterationsType getMetaOptimizerIterations() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.NumIterationsType result = org.tensorflow.proto.framework.RewriterConfig.NumIterationsType.valueOf(metaOptimizerIterations_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.NumIterationsType.UNRECOGNIZED : result;
  }

  public static final int MIN_GRAPH_NODES_FIELD_NUMBER = 17;
  private int minGraphNodes_;
  /**
   * <pre>
   * The minimum number of nodes in a graph to optimizer. For smaller graphs,
   * optimization is skipped.
   * 0 means the system picks an appropriate number.
   * &lt; 0 means do not skip optimization.
   * </pre>
   *
   * <code>int32 min_graph_nodes = 17;</code>
   * @return The minGraphNodes.
   */
  @java.lang.Override
  public int getMinGraphNodes() {
    return minGraphNodes_;
  }

  public static final int EXPERIMENTAL_DISABLE_COMPRESSED_TENSOR_OPTIMIZATION_FIELD_NUMBER = 26;
  private boolean experimentalDisableCompressedTensorOptimization_;
  /**
   * <pre>
   * Disable optimizations that assume compressed tensors. Note that this flag
   * is experimental and may be removed in the future.
   * </pre>
   *
   * <code>bool experimental_disable_compressed_tensor_optimization = 26;</code>
   * @return The experimentalDisableCompressedTensorOptimization.
   */
  @java.lang.Override
  public boolean getExperimentalDisableCompressedTensorOptimization() {
    return experimentalDisableCompressedTensorOptimization_;
  }

  public static final int EXPERIMENTAL_DISABLE_FOLDING_QUANTIZATION_EMULATION_FIELD_NUMBER = 27;
  private boolean experimentalDisableFoldingQuantizationEmulation_;
  /**
   * <pre>
   * Disable folding quantization emulation ops such as FakeQuantWithMinMax* and
   * QuantizeAndDequantize*. Some compilers (e.g. the TF-to-tflite converter)
   * have to extract quantization configs (e.g. min/max range, number of bits,
   * and per-channel) from the quantization emulation ops. Note that this flag
   * is experimental and may be removed in the future. See b/174138564 for more
   * details.
   * </pre>
   *
   * <code>bool experimental_disable_folding_quantization_emulation = 27;</code>
   * @return The experimentalDisableFoldingQuantizationEmulation.
   */
  @java.lang.Override
  public boolean getExperimentalDisableFoldingQuantizationEmulation() {
    return experimentalDisableFoldingQuantizationEmulation_;
  }

  public static final int MEMORY_OPTIMIZATION_FIELD_NUMBER = 4;
  private int memoryOptimization_;
  /**
   * <pre>
   * Configures memory optimization passes through the meta-optimizer. Has no
   * effect on manually requested memory optimization passes in the optimizers
   * field.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
   * @return The enum numeric value on the wire for memoryOptimization.
   */
  @java.lang.Override public int getMemoryOptimizationValue() {
    return memoryOptimization_;
  }
  /**
   * <pre>
   * Configures memory optimization passes through the meta-optimizer. Has no
   * effect on manually requested memory optimization passes in the optimizers
   * field.
   * </pre>
   *
   * <code>.tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
   * @return The memoryOptimization.
   */
  @java.lang.Override public org.tensorflow.proto.framework.RewriterConfig.MemOptType getMemoryOptimization() {
    @SuppressWarnings("deprecation")
    org.tensorflow.proto.framework.RewriterConfig.MemOptType result = org.tensorflow.proto.framework.RewriterConfig.MemOptType.valueOf(memoryOptimization_);
    return result == null ? org.tensorflow.proto.framework.RewriterConfig.MemOptType.UNRECOGNIZED : result;
  }

  public static final int MEMORY_OPTIMIZER_TARGET_NODE_NAME_SCOPE_FIELD_NUMBER = 6;
  private volatile java.lang.Object memoryOptimizerTargetNodeNameScope_;
  /**
   * <pre>
   * A node name scope for node names which are valid outputs of recomputations.
   * Inputs to nodes that match this scope may be recomputed (subject either to
   * manual annotation of those input nodes or to manual annotation and
   * heuristics depending on memory_optimization), but the nodes themselves will
   * not be recomputed. This matches any sub-scopes as well, meaning the scope
   * can appear not just as a top-level scope. For example, if the value is
   * "gradients/", the default, it will match node name "gradients/foo",
   * "foo/gradients/bar", but not "foo_gradients/"
   * </pre>
   *
   * <code>string memory_optimizer_target_node_name_scope = 6;</code>
   * @return The memoryOptimizerTargetNodeNameScope.
   */
  @java.lang.Override
  public java.lang.String getMemoryOptimizerTargetNodeNameScope() {
    java.lang.Object ref = memoryOptimizerTargetNodeNameScope_;
    if (ref instanceof java.lang.String) {
      return (java.lang.String) ref;
    } else {
      com.google.protobuf.ByteString bs = 
          (com.google.protobuf.ByteString) ref;
      java.lang.String s = bs.toStringUtf8();
      memoryOptimizerTargetNodeNameScope_ = s;
      return s;
    }
  }
  /**
   * <pre>
   * A node name scope for node names which are valid outputs of recomputations.
   * Inputs to nodes that match this scope may be recomputed (subject either to
   * manual annotation of those input nodes or to manual annotation and
   * heuristics depending on memory_optimization), but the nodes themselves will
   * not be recomputed. This matches any sub-scopes as well, meaning the scope
   * can appear not just as a top-level scope. For example, if the value is
   * "gradients/", the default, it will match node name "gradients/foo",
   * "foo/gradients/bar", but not "foo_gradients/"
   * </pre>
   *
   * <code>string memory_optimizer_target_node_name_scope = 6;</code>
   * @return The bytes for memoryOptimizerTargetNodeNameScope.
   */
  @java.lang.Override
  public com.google.protobuf.ByteString
      getMemoryOptimizerTargetNodeNameScopeBytes() {
    java.lang.Object ref = memoryOptimizerTargetNodeNameScope_;
    if (ref instanceof java.lang.String) {
      com.google.protobuf.ByteString b = 
          com.google.protobuf.ByteString.copyFromUtf8(
              (java.lang.String) ref);
      memoryOptimizerTargetNodeNameScope_ = b;
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  public static final int META_OPTIMIZER_TIMEOUT_MS_FIELD_NUMBER = 20;
  private long metaOptimizerTimeoutMs_;
  /**
   * <pre>
   * Maximum number of milliseconds to spend optimizing a single graph before
   * timing out. If less than or equal to 0 (default value) the optimizer will
   * never time out.
   * </pre>
   *
   * <code>int64 meta_optimizer_timeout_ms = 20;</code>
   * @return The metaOptimizerTimeoutMs.
   */
  @java.lang.Override
  public long getMetaOptimizerTimeoutMs() {
    return metaOptimizerTimeoutMs_;
  }

  public static final int AUTO_PARALLEL_FIELD_NUMBER = 5;
  private org.tensorflow.proto.framework.AutoParallelOptions autoParallel_;
  /**
   * <pre>
   * Configures AutoParallel optimization passes either through the
   * meta-optimizer or when manually specified through the optimizers field.
   * </pre>
   *
   * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
   * @return Whether the autoParallel field is set.
   */
  @java.lang.Override
  public boolean hasAutoParallel() {
    return autoParallel_ != null;
  }
  /**
   * <pre>
   * Configures AutoParallel optimization passes either through the
   * meta-optimizer or when manually specified through the optimizers field.
   * </pre>
   *
   * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
   * @return The autoParallel.
   */
  @java.lang.Override
  public org.tensorflow.proto.framework.AutoParallelOptions getAutoParallel() {
    return autoParallel_ == null ? org.tensorflow.proto.framework.AutoParallelOptions.getDefaultInstance() : autoParallel_;
  }
  /**
   * <pre>
   * Configures AutoParallel optimization passes either through the
   * meta-optimizer or when manually specified through the optimizers field.
   * </pre>
   *
   * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
   */
  @java.lang.Override
  public org.tensorflow.proto.framework.AutoParallelOptionsOrBuilder getAutoParallelOrBuilder() {
    return getAutoParallel();
  }

  public static final int FAIL_ON_OPTIMIZER_ERRORS_FIELD_NUMBER = 21;
  private boolean failOnOptimizerErrors_;
  /**
   * <pre>
   * If true, any optimization pass failing will cause the MetaOptimizer to
   * stop with an error. By default - or when set to false, failing passes are
   * skipped silently.
   * </pre>
   *
   * <code>bool fail_on_optimizer_errors = 21;</code>
   * @return The failOnOptimizerErrors.
   */
  @java.lang.Override
  public boolean getFailOnOptimizerErrors() {
    return failOnOptimizerErrors_;
  }

  public static final int SCOPED_ALLOCATOR_OPTS_FIELD_NUMBER = 16;
  private org.tensorflow.proto.framework.ScopedAllocatorOptions scopedAllocatorOpts_;
  /**
   * <code>.tensorflow.ScopedAllocatorOptions scoped_allocator_opts = 16;</code>
   * @return Whether the scopedAllocatorOpts field is set.
   */
  @java.lang.Override
  public boolean hasScopedAllocatorOpts() {
    return scopedAllocatorOpts_ != null;
  }
  /**
   * <code>.tensorflow.ScopedAllocatorOptions scoped_allocator_opts = 16;</code>
   * @return The scopedAllocatorOpts.
   */
  @java.lang.Override
  public org.tensorflow.proto.framework.ScopedAllocatorOptions getScopedAllocatorOpts() {
    return scopedAllocatorOpts_ == null ? org.tensorflow.proto.framework.ScopedAllocatorOptions.getDefaultInstance() : scopedAllocatorOpts_;
  }
  /**
   * <code>.tensorflow.ScopedAllocatorOptions scoped_allocator_opts = 16;</code>
   */
  @java.lang.Override
  public org.tensorflow.proto.framework.ScopedAllocatorOptionsOrBuilder getScopedAllocatorOptsOrBuilder() {
    return getScopedAllocatorOpts();
  }

  public static final int OPTIMIZERS_FIELD_NUMBER = 100;
  private com.google.protobuf.LazyStringList optimizers_;
  /**
   * <pre>
   * If non-empty, will use this as an alternative way to specify a list of
   * optimizations to turn on and the order of the optimizations (replacing the
   * meta-optimizer).
   * Of the RewriterConfig options, only the AutoParallel configuration options
   * (the auto_parallel field) apply to manually requested optimization passes
   * ("autoparallel"). Memory optimization passes ("memory") invoked here are
   * not configurable (in contrast to memory optimization passes through the
   * meta-optimizer) and act only on manual op annotations.
   * Custom optimizers (see custom_optimizers) that are not part of this
   * schedule will be run after - in the order that they were specified.
   * </pre>
   *
   * <code>repeated string optimizers = 100;</code>
   * @return A list containing the optimizers.
   */
  public com.google.protobuf.ProtocolStringList
      getOptimizersList() {
    return optimizers_;
  }
  /**
   * <pre>
   * If non-empty, will use this as an alternative way to specify a list of
   * optimizations to turn on and the order of the optimizations (replacing the
   * meta-optimizer).
   * Of the RewriterConfig options, only the AutoParallel configuration options
   * (the auto_parallel field) apply to manually requested optimization passes
   * ("autoparallel"). Memory optimization passes ("memory") invoked here are
   * not configurable (in contrast to memory optimization passes through the
   * meta-optimizer) and act only on manual op annotations.
   * Custom optimizers (see custom_optimizers) that are not part of this
   * schedule will be run after - in the order that they were specified.
   * </pre>
   *
   * <code>repeated string optimizers = 100;</code>
   * @return The count of optimizers.
   */
  public int getOptimizersCount() {
    return optimizers_.size();
  }
  /**
   * <pre>
   * If non-empty, will use this as an alternative way to specify a list of
   * optimizations to turn on and the order of the optimizations (replacing the
   * meta-optimizer).
   * Of the RewriterConfig options, only the AutoParallel configuration options
   * (the auto_parallel field) apply to manually requested optimization passes
   * ("autoparallel"). Memory optimization passes ("memory") invoked here are
   * not configurable (in contrast to memory optimization passes through the
   * meta-optimizer) and act only on manual op annotations.
   * Custom optimizers (see custom_optimizers) that are not part of this
   * schedule will be run after - in the order that they were specified.
   * </pre>
   *
   * <code>repeated string optimizers = 100;</code>
   * @param index The index of the element to return.
   * @return The optimizers at the given index.
   */
  public java.lang.String getOptimizers(int index) {
    return optimizers_.get(index);
  }
  /**
   * <pre>
   * If non-empty, will use this as an alternative way to specify a list of
   * optimizations to turn on and the order of the optimizations (replacing the
   * meta-optimizer).
   * Of the RewriterConfig options, only the AutoParallel configuration options
   * (the auto_parallel field) apply to manually requested optimization passes
   * ("autoparallel"). Memory optimization passes ("memory") invoked here are
   * not configurable (in contrast to memory optimization passes through the
   * meta-optimizer) and act only on manual op annotations.
   * Custom optimizers (see custom_optimizers) that are not part of this
   * schedule will be run after - in the order that they were specified.
   * </pre>
   *
   * <code>repeated string optimizers = 100;</code>
   * @param index The index of the value to return.
   * @return The bytes of the optimizers at the given index.
   */
  public com.google.protobuf.ByteString
      getOptimizersBytes(int index) {
    return optimizers_.getByteString(index);
  }

  public static final int CUSTOM_OPTIMIZERS_FIELD_NUMBER = 200;
  private java.util.List<org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer> customOptimizers_;
  /**
   * <pre>
   * list of CustomGraphOptimizers to apply.
   * </pre>
   *
   * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
   */
  @java.lang.Override
  public java.util.List<org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer> getCustomOptimizersList() {
    return customOptimizers_;
  }
  /**
   * <pre>
   * list of CustomGraphOptimizers to apply.
   * </pre>
   *
   * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
   */
  @java.lang.Override
  public java.util.List<? extends org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizerOrBuilder> 
      getCustomOptimizersOrBuilderList() {
    return customOptimizers_;
  }
  /**
   * <pre>
   * list of CustomGraphOptimizers to apply.
   * </pre>
   *
   * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
   */
  @java.lang.Override
  public int getCustomOptimizersCount() {
    return customOptimizers_.size();
  }
  /**
   * <pre>
   * list of CustomGraphOptimizers to apply.
   * </pre>
   *
   * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
   */
  @java.lang.Override
  public org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer getCustomOptimizers(int index) {
    return customOptimizers_.get(index);
  }
  /**
   * <pre>
   * list of CustomGraphOptimizers to apply.
   * </pre>
   *
   * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
   */
  @java.lang.Override
  public org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizerOrBuilder getCustomOptimizersOrBuilder(
      int index) {
    return customOptimizers_.get(index);
  }

  public static final int INTER_OPTIMIZER_VERIFIER_CONFIG_FIELD_NUMBER = 300;
  private org.tensorflow.proto.framework.VerifierConfig interOptimizerVerifierConfig_;
  /**
   * <pre>
   * VerifierConfig specifying the verifiers to be run after every optimizer.
   * </pre>
   *
   * <code>.tensorflow.VerifierConfig inter_optimizer_verifier_config = 300;</code>
   * @return Whether the interOptimizerVerifierConfig field is set.
   */
  @java.lang.Override
  public boolean hasInterOptimizerVerifierConfig() {
    return interOptimizerVerifierConfig_ != null;
  }
  /**
   * <pre>
   * VerifierConfig specifying the verifiers to be run after every optimizer.
   * </pre>
   *
   * <code>.tensorflow.VerifierConfig inter_optimizer_verifier_config = 300;</code>
   * @return The interOptimizerVerifierConfig.
   */
  @java.lang.Override
  public org.tensorflow.proto.framework.VerifierConfig getInterOptimizerVerifierConfig() {
    return interOptimizerVerifierConfig_ == null ? org.tensorflow.proto.framework.VerifierConfig.getDefaultInstance() : interOptimizerVerifierConfig_;
  }
  /**
   * <pre>
   * VerifierConfig specifying the verifiers to be run after every optimizer.
   * </pre>
   *
   * <code>.tensorflow.VerifierConfig inter_optimizer_verifier_config = 300;</code>
   */
  @java.lang.Override
  public org.tensorflow.proto.framework.VerifierConfigOrBuilder getInterOptimizerVerifierConfigOrBuilder() {
    return getInterOptimizerVerifierConfig();
  }

  public static final int POST_OPTIMIZATION_VERIFIER_CONFIG_FIELD_NUMBER = 301;
  private org.tensorflow.proto.framework.VerifierConfig postOptimizationVerifierConfig_;
  /**
   * <pre>
   * VerifierConfig specifying the verifiers to be run at the end, after all
   * optimizers have run.
   * </pre>
   *
   * <code>.tensorflow.VerifierConfig post_optimization_verifier_config = 301;</code>
   * @return Whether the postOptimizationVerifierConfig field is set.
   */
  @java.lang.Override
  public boolean hasPostOptimizationVerifierConfig() {
    return postOptimizationVerifierConfig_ != null;
  }
  /**
   * <pre>
   * VerifierConfig specifying the verifiers to be run at the end, after all
   * optimizers have run.
   * </pre>
   *
   * <code>.tensorflow.VerifierConfig post_optimization_verifier_config = 301;</code>
   * @return The postOptimizationVerifierConfig.
   */
  @java.lang.Override
  public org.tensorflow.proto.framework.VerifierConfig getPostOptimizationVerifierConfig() {
    return postOptimizationVerifierConfig_ == null ? org.tensorflow.proto.framework.VerifierConfig.getDefaultInstance() : postOptimizationVerifierConfig_;
  }
  /**
   * <pre>
   * VerifierConfig specifying the verifiers to be run at the end, after all
   * optimizers have run.
   * </pre>
   *
   * <code>.tensorflow.VerifierConfig post_optimization_verifier_config = 301;</code>
   */
  @java.lang.Override
  public org.tensorflow.proto.framework.VerifierConfigOrBuilder getPostOptimizationVerifierConfigOrBuilder() {
    return getPostOptimizationVerifierConfig();
  }

  private byte memoizedIsInitialized = -1;
  @java.lang.Override
  public final boolean isInitialized() {
    byte isInitialized = memoizedIsInitialized;
    if (isInitialized == 1) return true;
    if (isInitialized == 0) return false;

    memoizedIsInitialized = 1;
    return true;
  }

  @java.lang.Override
  public void writeTo(com.google.protobuf.CodedOutputStream output)
                      throws java.io.IOException {
    if (layoutOptimizer_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(1, layoutOptimizer_);
    }
    if (disableModelPruning_ != false) {
      output.writeBool(2, disableModelPruning_);
    }
    if (constantFolding_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(3, constantFolding_);
    }
    if (memoryOptimization_ != org.tensorflow.proto.framework.RewriterConfig.MemOptType.DEFAULT_MEM_OPT.getNumber()) {
      output.writeEnum(4, memoryOptimization_);
    }
    if (autoParallel_ != null) {
      output.writeMessage(5, getAutoParallel());
    }
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(memoryOptimizerTargetNodeNameScope_)) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 6, memoryOptimizerTargetNodeNameScope_);
    }
    if (arithmeticOptimization_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(7, arithmeticOptimization_);
    }
    if (dependencyOptimization_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(8, dependencyOptimization_);
    }
    if (loopOptimization_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(9, loopOptimization_);
    }
    if (functionOptimization_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(10, functionOptimization_);
    }
    if (debugStripper_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(11, debugStripper_);
    }
    if (metaOptimizerIterations_ != org.tensorflow.proto.framework.RewriterConfig.NumIterationsType.DEFAULT_NUM_ITERS.getNumber()) {
      output.writeEnum(12, metaOptimizerIterations_);
    }
    if (shapeOptimization_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(13, shapeOptimization_);
    }
    if (remapping_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(14, remapping_);
    }
    if (scopedAllocatorOptimization_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(15, scopedAllocatorOptimization_);
    }
    if (scopedAllocatorOpts_ != null) {
      output.writeMessage(16, getScopedAllocatorOpts());
    }
    if (minGraphNodes_ != 0) {
      output.writeInt32(17, minGraphNodes_);
    }
    if (pinToHostOptimization_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(18, pinToHostOptimization_);
    }
    if (disableMetaOptimizer_ != false) {
      output.writeBool(19, disableMetaOptimizer_);
    }
    if (metaOptimizerTimeoutMs_ != 0L) {
      output.writeInt64(20, metaOptimizerTimeoutMs_);
    }
    if (failOnOptimizerErrors_ != false) {
      output.writeBool(21, failOnOptimizerErrors_);
    }
    if (implementationSelector_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(22, implementationSelector_);
    }
    if (autoMixedPrecision_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(23, autoMixedPrecision_);
    }
    if (commonSubgraphElimination_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(24, commonSubgraphElimination_);
    }
    if (autoMixedPrecisionMkl_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(25, autoMixedPrecisionMkl_);
    }
    if (experimentalDisableCompressedTensorOptimization_ != false) {
      output.writeBool(26, experimentalDisableCompressedTensorOptimization_);
    }
    if (experimentalDisableFoldingQuantizationEmulation_ != false) {
      output.writeBool(27, experimentalDisableFoldingQuantizationEmulation_);
    }
    if (usePluginOptimizers_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(28, usePluginOptimizers_);
    }
    if (autoMixedPrecisionCpu_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(29, autoMixedPrecisionCpu_);
    }
    if (experimentalConditionalCodeMotion_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(30, experimentalConditionalCodeMotion_);
    }
    if (autoMixedPrecisionOnednnBfloat16_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      output.writeEnum(31, autoMixedPrecisionOnednnBfloat16_);
    }
    if (cpuLayoutConversion_ != org.tensorflow.proto.framework.RewriterConfig.CpuLayout.NO_CONVERSION_ON_CPU.getNumber()) {
      output.writeEnum(50, cpuLayoutConversion_);
    }
    for (int i = 0; i < optimizers_.size(); i++) {
      com.google.protobuf.GeneratedMessageV3.writeString(output, 100, optimizers_.getRaw(i));
    }
    for (int i = 0; i < customOptimizers_.size(); i++) {
      output.writeMessage(200, customOptimizers_.get(i));
    }
    if (interOptimizerVerifierConfig_ != null) {
      output.writeMessage(300, getInterOptimizerVerifierConfig());
    }
    if (postOptimizationVerifierConfig_ != null) {
      output.writeMessage(301, getPostOptimizationVerifierConfig());
    }
    getUnknownFields().writeTo(output);
  }

  @java.lang.Override
  public int getSerializedSize() {
    int size = memoizedSize;
    if (size != -1) return size;

    size = 0;
    if (layoutOptimizer_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(1, layoutOptimizer_);
    }
    if (disableModelPruning_ != false) {
      size += com.google.protobuf.CodedOutputStream
        .computeBoolSize(2, disableModelPruning_);
    }
    if (constantFolding_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(3, constantFolding_);
    }
    if (memoryOptimization_ != org.tensorflow.proto.framework.RewriterConfig.MemOptType.DEFAULT_MEM_OPT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(4, memoryOptimization_);
    }
    if (autoParallel_ != null) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(5, getAutoParallel());
    }
    if (!com.google.protobuf.GeneratedMessageV3.isStringEmpty(memoryOptimizerTargetNodeNameScope_)) {
      size += com.google.protobuf.GeneratedMessageV3.computeStringSize(6, memoryOptimizerTargetNodeNameScope_);
    }
    if (arithmeticOptimization_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(7, arithmeticOptimization_);
    }
    if (dependencyOptimization_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(8, dependencyOptimization_);
    }
    if (loopOptimization_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(9, loopOptimization_);
    }
    if (functionOptimization_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(10, functionOptimization_);
    }
    if (debugStripper_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(11, debugStripper_);
    }
    if (metaOptimizerIterations_ != org.tensorflow.proto.framework.RewriterConfig.NumIterationsType.DEFAULT_NUM_ITERS.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(12, metaOptimizerIterations_);
    }
    if (shapeOptimization_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(13, shapeOptimization_);
    }
    if (remapping_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(14, remapping_);
    }
    if (scopedAllocatorOptimization_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(15, scopedAllocatorOptimization_);
    }
    if (scopedAllocatorOpts_ != null) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(16, getScopedAllocatorOpts());
    }
    if (minGraphNodes_ != 0) {
      size += com.google.protobuf.CodedOutputStream
        .computeInt32Size(17, minGraphNodes_);
    }
    if (pinToHostOptimization_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(18, pinToHostOptimization_);
    }
    if (disableMetaOptimizer_ != false) {
      size += com.google.protobuf.CodedOutputStream
        .computeBoolSize(19, disableMetaOptimizer_);
    }
    if (metaOptimizerTimeoutMs_ != 0L) {
      size += com.google.protobuf.CodedOutputStream
        .computeInt64Size(20, metaOptimizerTimeoutMs_);
    }
    if (failOnOptimizerErrors_ != false) {
      size += com.google.protobuf.CodedOutputStream
        .computeBoolSize(21, failOnOptimizerErrors_);
    }
    if (implementationSelector_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(22, implementationSelector_);
    }
    if (autoMixedPrecision_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(23, autoMixedPrecision_);
    }
    if (commonSubgraphElimination_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(24, commonSubgraphElimination_);
    }
    if (autoMixedPrecisionMkl_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(25, autoMixedPrecisionMkl_);
    }
    if (experimentalDisableCompressedTensorOptimization_ != false) {
      size += com.google.protobuf.CodedOutputStream
        .computeBoolSize(26, experimentalDisableCompressedTensorOptimization_);
    }
    if (experimentalDisableFoldingQuantizationEmulation_ != false) {
      size += com.google.protobuf.CodedOutputStream
        .computeBoolSize(27, experimentalDisableFoldingQuantizationEmulation_);
    }
    if (usePluginOptimizers_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(28, usePluginOptimizers_);
    }
    if (autoMixedPrecisionCpu_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(29, autoMixedPrecisionCpu_);
    }
    if (experimentalConditionalCodeMotion_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(30, experimentalConditionalCodeMotion_);
    }
    if (autoMixedPrecisionOnednnBfloat16_ != org.tensorflow.proto.framework.RewriterConfig.Toggle.DEFAULT.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(31, autoMixedPrecisionOnednnBfloat16_);
    }
    if (cpuLayoutConversion_ != org.tensorflow.proto.framework.RewriterConfig.CpuLayout.NO_CONVERSION_ON_CPU.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(50, cpuLayoutConversion_);
    }
    {
      int dataSize = 0;
      for (int i = 0; i < optimizers_.size(); i++) {
        dataSize += computeStringSizeNoTag(optimizers_.getRaw(i));
      }
      size += dataSize;
      size += 2 * getOptimizersList().size();
    }
    for (int i = 0; i < customOptimizers_.size(); i++) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(200, customOptimizers_.get(i));
    }
    if (interOptimizerVerifierConfig_ != null) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(300, getInterOptimizerVerifierConfig());
    }
    if (postOptimizationVerifierConfig_ != null) {
      size += com.google.protobuf.CodedOutputStream
        .computeMessageSize(301, getPostOptimizationVerifierConfig());
    }
    size += getUnknownFields().getSerializedSize();
    memoizedSize = size;
    return size;
  }

  @java.lang.Override
  public boolean equals(final java.lang.Object obj) {
    if (obj == this) {
     return true;
    }
    if (!(obj instanceof org.tensorflow.proto.framework.RewriterConfig)) {
      return super.equals(obj);
    }
    org.tensorflow.proto.framework.RewriterConfig other = (org.tensorflow.proto.framework.RewriterConfig) obj;

    if (cpuLayoutConversion_ != other.cpuLayoutConversion_) return false;
    if (layoutOptimizer_ != other.layoutOptimizer_) return false;
    if (constantFolding_ != other.constantFolding_) return false;
    if (shapeOptimization_ != other.shapeOptimization_) return false;
    if (remapping_ != other.remapping_) return false;
    if (commonSubgraphElimination_ != other.commonSubgraphElimination_) return false;
    if (arithmeticOptimization_ != other.arithmeticOptimization_) return false;
    if (dependencyOptimization_ != other.dependencyOptimization_) return false;
    if (loopOptimization_ != other.loopOptimization_) return false;
    if (functionOptimization_ != other.functionOptimization_) return false;
    if (debugStripper_ != other.debugStripper_) return false;
    if (getDisableModelPruning()
        != other.getDisableModelPruning()) return false;
    if (scopedAllocatorOptimization_ != other.scopedAllocatorOptimization_) return false;
    if (pinToHostOptimization_ != other.pinToHostOptimization_) return false;
    if (implementationSelector_ != other.implementationSelector_) return false;
    if (autoMixedPrecision_ != other.autoMixedPrecision_) return false;
    if (autoMixedPrecisionMkl_ != other.autoMixedPrecisionMkl_) return false;
    if (autoMixedPrecisionOnednnBfloat16_ != other.autoMixedPrecisionOnednnBfloat16_) return false;
    if (autoMixedPrecisionCpu_ != other.autoMixedPrecisionCpu_) return false;
    if (getDisableMetaOptimizer()
        != other.getDisableMetaOptimizer()) return false;
    if (usePluginOptimizers_ != other.usePluginOptimizers_) return false;
    if (experimentalConditionalCodeMotion_ != other.experimentalConditionalCodeMotion_) return false;
    if (metaOptimizerIterations_ != other.metaOptimizerIterations_) return false;
    if (getMinGraphNodes()
        != other.getMinGraphNodes()) return false;
    if (getExperimentalDisableCompressedTensorOptimization()
        != other.getExperimentalDisableCompressedTensorOptimization()) return false;
    if (getExperimentalDisableFoldingQuantizationEmulation()
        != other.getExperimentalDisableFoldingQuantizationEmulation()) return false;
    if (memoryOptimization_ != other.memoryOptimization_) return false;
    if (!getMemoryOptimizerTargetNodeNameScope()
        .equals(other.getMemoryOptimizerTargetNodeNameScope())) return false;
    if (getMetaOptimizerTimeoutMs()
        != other.getMetaOptimizerTimeoutMs()) return false;
    if (hasAutoParallel() != other.hasAutoParallel()) return false;
    if (hasAutoParallel()) {
      if (!getAutoParallel()
          .equals(other.getAutoParallel())) return false;
    }
    if (getFailOnOptimizerErrors()
        != other.getFailOnOptimizerErrors()) return false;
    if (hasScopedAllocatorOpts() != other.hasScopedAllocatorOpts()) return false;
    if (hasScopedAllocatorOpts()) {
      if (!getScopedAllocatorOpts()
          .equals(other.getScopedAllocatorOpts())) return false;
    }
    if (!getOptimizersList()
        .equals(other.getOptimizersList())) return false;
    if (!getCustomOptimizersList()
        .equals(other.getCustomOptimizersList())) return false;
    if (hasInterOptimizerVerifierConfig() != other.hasInterOptimizerVerifierConfig()) return false;
    if (hasInterOptimizerVerifierConfig()) {
      if (!getInterOptimizerVerifierConfig()
          .equals(other.getInterOptimizerVerifierConfig())) return false;
    }
    if (hasPostOptimizationVerifierConfig() != other.hasPostOptimizationVerifierConfig()) return false;
    if (hasPostOptimizationVerifierConfig()) {
      if (!getPostOptimizationVerifierConfig()
          .equals(other.getPostOptimizationVerifierConfig())) return false;
    }
    if (!getUnknownFields().equals(other.getUnknownFields())) return false;
    return true;
  }

  @java.lang.Override
  public int hashCode() {
    if (memoizedHashCode != 0) {
      return memoizedHashCode;
    }
    int hash = 41;
    hash = (19 * hash) + getDescriptor().hashCode();
    hash = (37 * hash) + CPU_LAYOUT_CONVERSION_FIELD_NUMBER;
    hash = (53 * hash) + cpuLayoutConversion_;
    hash = (37 * hash) + LAYOUT_OPTIMIZER_FIELD_NUMBER;
    hash = (53 * hash) + layoutOptimizer_;
    hash = (37 * hash) + CONSTANT_FOLDING_FIELD_NUMBER;
    hash = (53 * hash) + constantFolding_;
    hash = (37 * hash) + SHAPE_OPTIMIZATION_FIELD_NUMBER;
    hash = (53 * hash) + shapeOptimization_;
    hash = (37 * hash) + REMAPPING_FIELD_NUMBER;
    hash = (53 * hash) + remapping_;
    hash = (37 * hash) + COMMON_SUBGRAPH_ELIMINATION_FIELD_NUMBER;
    hash = (53 * hash) + commonSubgraphElimination_;
    hash = (37 * hash) + ARITHMETIC_OPTIMIZATION_FIELD_NUMBER;
    hash = (53 * hash) + arithmeticOptimization_;
    hash = (37 * hash) + DEPENDENCY_OPTIMIZATION_FIELD_NUMBER;
    hash = (53 * hash) + dependencyOptimization_;
    hash = (37 * hash) + LOOP_OPTIMIZATION_FIELD_NUMBER;
    hash = (53 * hash) + loopOptimization_;
    hash = (37 * hash) + FUNCTION_OPTIMIZATION_FIELD_NUMBER;
    hash = (53 * hash) + functionOptimization_;
    hash = (37 * hash) + DEBUG_STRIPPER_FIELD_NUMBER;
    hash = (53 * hash) + debugStripper_;
    hash = (37 * hash) + DISABLE_MODEL_PRUNING_FIELD_NUMBER;
    hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
        getDisableModelPruning());
    hash = (37 * hash) + SCOPED_ALLOCATOR_OPTIMIZATION_FIELD_NUMBER;
    hash = (53 * hash) + scopedAllocatorOptimization_;
    hash = (37 * hash) + PIN_TO_HOST_OPTIMIZATION_FIELD_NUMBER;
    hash = (53 * hash) + pinToHostOptimization_;
    hash = (37 * hash) + IMPLEMENTATION_SELECTOR_FIELD_NUMBER;
    hash = (53 * hash) + implementationSelector_;
    hash = (37 * hash) + AUTO_MIXED_PRECISION_FIELD_NUMBER;
    hash = (53 * hash) + autoMixedPrecision_;
    hash = (37 * hash) + AUTO_MIXED_PRECISION_MKL_FIELD_NUMBER;
    hash = (53 * hash) + autoMixedPrecisionMkl_;
    hash = (37 * hash) + AUTO_MIXED_PRECISION_ONEDNN_BFLOAT16_FIELD_NUMBER;
    hash = (53 * hash) + autoMixedPrecisionOnednnBfloat16_;
    hash = (37 * hash) + AUTO_MIXED_PRECISION_CPU_FIELD_NUMBER;
    hash = (53 * hash) + autoMixedPrecisionCpu_;
    hash = (37 * hash) + DISABLE_META_OPTIMIZER_FIELD_NUMBER;
    hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
        getDisableMetaOptimizer());
    hash = (37 * hash) + USE_PLUGIN_OPTIMIZERS_FIELD_NUMBER;
    hash = (53 * hash) + usePluginOptimizers_;
    hash = (37 * hash) + EXPERIMENTAL_CONDITIONAL_CODE_MOTION_FIELD_NUMBER;
    hash = (53 * hash) + experimentalConditionalCodeMotion_;
    hash = (37 * hash) + META_OPTIMIZER_ITERATIONS_FIELD_NUMBER;
    hash = (53 * hash) + metaOptimizerIterations_;
    hash = (37 * hash) + MIN_GRAPH_NODES_FIELD_NUMBER;
    hash = (53 * hash) + getMinGraphNodes();
    hash = (37 * hash) + EXPERIMENTAL_DISABLE_COMPRESSED_TENSOR_OPTIMIZATION_FIELD_NUMBER;
    hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
        getExperimentalDisableCompressedTensorOptimization());
    hash = (37 * hash) + EXPERIMENTAL_DISABLE_FOLDING_QUANTIZATION_EMULATION_FIELD_NUMBER;
    hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
        getExperimentalDisableFoldingQuantizationEmulation());
    hash = (37 * hash) + MEMORY_OPTIMIZATION_FIELD_NUMBER;
    hash = (53 * hash) + memoryOptimization_;
    hash = (37 * hash) + MEMORY_OPTIMIZER_TARGET_NODE_NAME_SCOPE_FIELD_NUMBER;
    hash = (53 * hash) + getMemoryOptimizerTargetNodeNameScope().hashCode();
    hash = (37 * hash) + META_OPTIMIZER_TIMEOUT_MS_FIELD_NUMBER;
    hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
        getMetaOptimizerTimeoutMs());
    if (hasAutoParallel()) {
      hash = (37 * hash) + AUTO_PARALLEL_FIELD_NUMBER;
      hash = (53 * hash) + getAutoParallel().hashCode();
    }
    hash = (37 * hash) + FAIL_ON_OPTIMIZER_ERRORS_FIELD_NUMBER;
    hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
        getFailOnOptimizerErrors());
    if (hasScopedAllocatorOpts()) {
      hash = (37 * hash) + SCOPED_ALLOCATOR_OPTS_FIELD_NUMBER;
      hash = (53 * hash) + getScopedAllocatorOpts().hashCode();
    }
    if (getOptimizersCount() > 0) {
      hash = (37 * hash) + OPTIMIZERS_FIELD_NUMBER;
      hash = (53 * hash) + getOptimizersList().hashCode();
    }
    if (getCustomOptimizersCount() > 0) {
      hash = (37 * hash) + CUSTOM_OPTIMIZERS_FIELD_NUMBER;
      hash = (53 * hash) + getCustomOptimizersList().hashCode();
    }
    if (hasInterOptimizerVerifierConfig()) {
      hash = (37 * hash) + INTER_OPTIMIZER_VERIFIER_CONFIG_FIELD_NUMBER;
      hash = (53 * hash) + getInterOptimizerVerifierConfig().hashCode();
    }
    if (hasPostOptimizationVerifierConfig()) {
      hash = (37 * hash) + POST_OPTIMIZATION_VERIFIER_CONFIG_FIELD_NUMBER;
      hash = (53 * hash) + getPostOptimizationVerifierConfig().hashCode();
    }
    hash = (29 * hash) + getUnknownFields().hashCode();
    memoizedHashCode = hash;
    return hash;
  }

  public static org.tensorflow.proto.framework.RewriterConfig parseFrom(
      java.nio.ByteBuffer data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static org.tensorflow.proto.framework.RewriterConfig parseFrom(
      java.nio.ByteBuffer data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static org.tensorflow.proto.framework.RewriterConfig parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static org.tensorflow.proto.framework.RewriterConfig parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static org.tensorflow.proto.framework.RewriterConfig parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static org.tensorflow.proto.framework.RewriterConfig parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static org.tensorflow.proto.framework.RewriterConfig parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static org.tensorflow.proto.framework.RewriterConfig parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }
  public static org.tensorflow.proto.framework.RewriterConfig parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input);
  }
  public static org.tensorflow.proto.framework.RewriterConfig parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
  }
  public static org.tensorflow.proto.framework.RewriterConfig parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input);
  }
  public static org.tensorflow.proto.framework.RewriterConfig parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessageV3
        .parseWithIOException(PARSER, input, extensionRegistry);
  }

  @java.lang.Override
  public Builder newBuilderForType() { return newBuilder(); }
  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }
  public static Builder newBuilder(org.tensorflow.proto.framework.RewriterConfig prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }
  @java.lang.Override
  public Builder toBuilder() {
    return this == DEFAULT_INSTANCE
        ? new Builder() : new Builder().mergeFrom(this);
  }

  @java.lang.Override
  protected Builder newBuilderForType(
      com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
    Builder builder = new Builder(parent);
    return builder;
  }
  /**
   * <pre>
   * Graph rewriting is experimental and subject to change, not covered by any
   * API stability guarantees.
   * </pre>
   *
   * Protobuf type {@code tensorflow.RewriterConfig}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
      // @@protoc_insertion_point(builder_implements:tensorflow.RewriterConfig)
      org.tensorflow.proto.framework.RewriterConfigOrBuilder {
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.tensorflow.proto.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_descriptor;
    }

    @java.lang.Override
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.tensorflow.proto.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.tensorflow.proto.framework.RewriterConfig.class, org.tensorflow.proto.framework.RewriterConfig.Builder.class);
    }

    // Construct using org.tensorflow.proto.framework.RewriterConfig.newBuilder()
    private Builder() {

    }

    private Builder(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      super(parent);

    }
    @java.lang.Override
    public Builder clear() {
      super.clear();
      cpuLayoutConversion_ = 0;

      layoutOptimizer_ = 0;

      constantFolding_ = 0;

      shapeOptimization_ = 0;

      remapping_ = 0;

      commonSubgraphElimination_ = 0;

      arithmeticOptimization_ = 0;

      dependencyOptimization_ = 0;

      loopOptimization_ = 0;

      functionOptimization_ = 0;

      debugStripper_ = 0;

      disableModelPruning_ = false;

      scopedAllocatorOptimization_ = 0;

      pinToHostOptimization_ = 0;

      implementationSelector_ = 0;

      autoMixedPrecision_ = 0;

      autoMixedPrecisionMkl_ = 0;

      autoMixedPrecisionOnednnBfloat16_ = 0;

      autoMixedPrecisionCpu_ = 0;

      disableMetaOptimizer_ = false;

      usePluginOptimizers_ = 0;

      experimentalConditionalCodeMotion_ = 0;

      metaOptimizerIterations_ = 0;

      minGraphNodes_ = 0;

      experimentalDisableCompressedTensorOptimization_ = false;

      experimentalDisableFoldingQuantizationEmulation_ = false;

      memoryOptimization_ = 0;

      memoryOptimizerTargetNodeNameScope_ = "";

      metaOptimizerTimeoutMs_ = 0L;

      if (autoParallelBuilder_ == null) {
        autoParallel_ = null;
      } else {
        autoParallel_ = null;
        autoParallelBuilder_ = null;
      }
      failOnOptimizerErrors_ = false;

      if (scopedAllocatorOptsBuilder_ == null) {
        scopedAllocatorOpts_ = null;
      } else {
        scopedAllocatorOpts_ = null;
        scopedAllocatorOptsBuilder_ = null;
      }
      optimizers_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      bitField0_ = (bitField0_ & ~0x00000001);
      if (customOptimizersBuilder_ == null) {
        customOptimizers_ = java.util.Collections.emptyList();
      } else {
        customOptimizers_ = null;
        customOptimizersBuilder_.clear();
      }
      bitField0_ = (bitField0_ & ~0x00000002);
      if (interOptimizerVerifierConfigBuilder_ == null) {
        interOptimizerVerifierConfig_ = null;
      } else {
        interOptimizerVerifierConfig_ = null;
        interOptimizerVerifierConfigBuilder_ = null;
      }
      if (postOptimizationVerifierConfigBuilder_ == null) {
        postOptimizationVerifierConfig_ = null;
      } else {
        postOptimizationVerifierConfig_ = null;
        postOptimizationVerifierConfigBuilder_ = null;
      }
      return this;
    }

    @java.lang.Override
    public com.google.protobuf.Descriptors.Descriptor
        getDescriptorForType() {
      return org.tensorflow.proto.framework.RewriterConfigProtos.internal_static_tensorflow_RewriterConfig_descriptor;
    }

    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig getDefaultInstanceForType() {
      return org.tensorflow.proto.framework.RewriterConfig.getDefaultInstance();
    }

    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig build() {
      org.tensorflow.proto.framework.RewriterConfig result = buildPartial();
      if (!result.isInitialized()) {
        throw newUninitializedMessageException(result);
      }
      return result;
    }

    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig buildPartial() {
      org.tensorflow.proto.framework.RewriterConfig result = new org.tensorflow.proto.framework.RewriterConfig(this);
      int from_bitField0_ = bitField0_;
      result.cpuLayoutConversion_ = cpuLayoutConversion_;
      result.layoutOptimizer_ = layoutOptimizer_;
      result.constantFolding_ = constantFolding_;
      result.shapeOptimization_ = shapeOptimization_;
      result.remapping_ = remapping_;
      result.commonSubgraphElimination_ = commonSubgraphElimination_;
      result.arithmeticOptimization_ = arithmeticOptimization_;
      result.dependencyOptimization_ = dependencyOptimization_;
      result.loopOptimization_ = loopOptimization_;
      result.functionOptimization_ = functionOptimization_;
      result.debugStripper_ = debugStripper_;
      result.disableModelPruning_ = disableModelPruning_;
      result.scopedAllocatorOptimization_ = scopedAllocatorOptimization_;
      result.pinToHostOptimization_ = pinToHostOptimization_;
      result.implementationSelector_ = implementationSelector_;
      result.autoMixedPrecision_ = autoMixedPrecision_;
      result.autoMixedPrecisionMkl_ = autoMixedPrecisionMkl_;
      result.autoMixedPrecisionOnednnBfloat16_ = autoMixedPrecisionOnednnBfloat16_;
      result.autoMixedPrecisionCpu_ = autoMixedPrecisionCpu_;
      result.disableMetaOptimizer_ = disableMetaOptimizer_;
      result.usePluginOptimizers_ = usePluginOptimizers_;
      result.experimentalConditionalCodeMotion_ = experimentalConditionalCodeMotion_;
      result.metaOptimizerIterations_ = metaOptimizerIterations_;
      result.minGraphNodes_ = minGraphNodes_;
      result.experimentalDisableCompressedTensorOptimization_ = experimentalDisableCompressedTensorOptimization_;
      result.experimentalDisableFoldingQuantizationEmulation_ = experimentalDisableFoldingQuantizationEmulation_;
      result.memoryOptimization_ = memoryOptimization_;
      result.memoryOptimizerTargetNodeNameScope_ = memoryOptimizerTargetNodeNameScope_;
      result.metaOptimizerTimeoutMs_ = metaOptimizerTimeoutMs_;
      if (autoParallelBuilder_ == null) {
        result.autoParallel_ = autoParallel_;
      } else {
        result.autoParallel_ = autoParallelBuilder_.build();
      }
      result.failOnOptimizerErrors_ = failOnOptimizerErrors_;
      if (scopedAllocatorOptsBuilder_ == null) {
        result.scopedAllocatorOpts_ = scopedAllocatorOpts_;
      } else {
        result.scopedAllocatorOpts_ = scopedAllocatorOptsBuilder_.build();
      }
      if (((bitField0_ & 0x00000001) != 0)) {
        optimizers_ = optimizers_.getUnmodifiableView();
        bitField0_ = (bitField0_ & ~0x00000001);
      }
      result.optimizers_ = optimizers_;
      if (customOptimizersBuilder_ == null) {
        if (((bitField0_ & 0x00000002) != 0)) {
          customOptimizers_ = java.util.Collections.unmodifiableList(customOptimizers_);
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.customOptimizers_ = customOptimizers_;
      } else {
        result.customOptimizers_ = customOptimizersBuilder_.build();
      }
      if (interOptimizerVerifierConfigBuilder_ == null) {
        result.interOptimizerVerifierConfig_ = interOptimizerVerifierConfig_;
      } else {
        result.interOptimizerVerifierConfig_ = interOptimizerVerifierConfigBuilder_.build();
      }
      if (postOptimizationVerifierConfigBuilder_ == null) {
        result.postOptimizationVerifierConfig_ = postOptimizationVerifierConfig_;
      } else {
        result.postOptimizationVerifierConfig_ = postOptimizationVerifierConfigBuilder_.build();
      }
      onBuilt();
      return result;
    }

    @java.lang.Override
    public Builder clone() {
      return super.clone();
    }
    @java.lang.Override
    public Builder setField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        java.lang.Object value) {
      return super.setField(field, value);
    }
    @java.lang.Override
    public Builder clearField(
        com.google.protobuf.Descriptors.FieldDescriptor field) {
      return super.clearField(field);
    }
    @java.lang.Override
    public Builder clearOneof(
        com.google.protobuf.Descriptors.OneofDescriptor oneof) {
      return super.clearOneof(oneof);
    }
    @java.lang.Override
    public Builder setRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        int index, java.lang.Object value) {
      return super.setRepeatedField(field, index, value);
    }
    @java.lang.Override
    public Builder addRepeatedField(
        com.google.protobuf.Descriptors.FieldDescriptor field,
        java.lang.Object value) {
      return super.addRepeatedField(field, value);
    }
    @java.lang.Override
    public Builder mergeFrom(com.google.protobuf.Message other) {
      if (other instanceof org.tensorflow.proto.framework.RewriterConfig) {
        return mergeFrom((org.tensorflow.proto.framework.RewriterConfig)other);
      } else {
        super.mergeFrom(other);
        return this;
      }
    }

    public Builder mergeFrom(org.tensorflow.proto.framework.RewriterConfig other) {
      if (other == org.tensorflow.proto.framework.RewriterConfig.getDefaultInstance()) return this;
      if (other.cpuLayoutConversion_ != 0) {
        setCpuLayoutConversionValue(other.getCpuLayoutConversionValue());
      }
      if (other.layoutOptimizer_ != 0) {
        setLayoutOptimizerValue(other.getLayoutOptimizerValue());
      }
      if (other.constantFolding_ != 0) {
        setConstantFoldingValue(other.getConstantFoldingValue());
      }
      if (other.shapeOptimization_ != 0) {
        setShapeOptimizationValue(other.getShapeOptimizationValue());
      }
      if (other.remapping_ != 0) {
        setRemappingValue(other.getRemappingValue());
      }
      if (other.commonSubgraphElimination_ != 0) {
        setCommonSubgraphEliminationValue(other.getCommonSubgraphEliminationValue());
      }
      if (other.arithmeticOptimization_ != 0) {
        setArithmeticOptimizationValue(other.getArithmeticOptimizationValue());
      }
      if (other.dependencyOptimization_ != 0) {
        setDependencyOptimizationValue(other.getDependencyOptimizationValue());
      }
      if (other.loopOptimization_ != 0) {
        setLoopOptimizationValue(other.getLoopOptimizationValue());
      }
      if (other.functionOptimization_ != 0) {
        setFunctionOptimizationValue(other.getFunctionOptimizationValue());
      }
      if (other.debugStripper_ != 0) {
        setDebugStripperValue(other.getDebugStripperValue());
      }
      if (other.getDisableModelPruning() != false) {
        setDisableModelPruning(other.getDisableModelPruning());
      }
      if (other.scopedAllocatorOptimization_ != 0) {
        setScopedAllocatorOptimizationValue(other.getScopedAllocatorOptimizationValue());
      }
      if (other.pinToHostOptimization_ != 0) {
        setPinToHostOptimizationValue(other.getPinToHostOptimizationValue());
      }
      if (other.implementationSelector_ != 0) {
        setImplementationSelectorValue(other.getImplementationSelectorValue());
      }
      if (other.autoMixedPrecision_ != 0) {
        setAutoMixedPrecisionValue(other.getAutoMixedPrecisionValue());
      }
      if (other.autoMixedPrecisionMkl_ != 0) {
        setAutoMixedPrecisionMklValue(other.getAutoMixedPrecisionMklValue());
      }
      if (other.autoMixedPrecisionOnednnBfloat16_ != 0) {
        setAutoMixedPrecisionOnednnBfloat16Value(other.getAutoMixedPrecisionOnednnBfloat16Value());
      }
      if (other.autoMixedPrecisionCpu_ != 0) {
        setAutoMixedPrecisionCpuValue(other.getAutoMixedPrecisionCpuValue());
      }
      if (other.getDisableMetaOptimizer() != false) {
        setDisableMetaOptimizer(other.getDisableMetaOptimizer());
      }
      if (other.usePluginOptimizers_ != 0) {
        setUsePluginOptimizersValue(other.getUsePluginOptimizersValue());
      }
      if (other.experimentalConditionalCodeMotion_ != 0) {
        setExperimentalConditionalCodeMotionValue(other.getExperimentalConditionalCodeMotionValue());
      }
      if (other.metaOptimizerIterations_ != 0) {
        setMetaOptimizerIterationsValue(other.getMetaOptimizerIterationsValue());
      }
      if (other.getMinGraphNodes() != 0) {
        setMinGraphNodes(other.getMinGraphNodes());
      }
      if (other.getExperimentalDisableCompressedTensorOptimization() != false) {
        setExperimentalDisableCompressedTensorOptimization(other.getExperimentalDisableCompressedTensorOptimization());
      }
      if (other.getExperimentalDisableFoldingQuantizationEmulation() != false) {
        setExperimentalDisableFoldingQuantizationEmulation(other.getExperimentalDisableFoldingQuantizationEmulation());
      }
      if (other.memoryOptimization_ != 0) {
        setMemoryOptimizationValue(other.getMemoryOptimizationValue());
      }
      if (!other.getMemoryOptimizerTargetNodeNameScope().isEmpty()) {
        memoryOptimizerTargetNodeNameScope_ = other.memoryOptimizerTargetNodeNameScope_;
        onChanged();
      }
      if (other.getMetaOptimizerTimeoutMs() != 0L) {
        setMetaOptimizerTimeoutMs(other.getMetaOptimizerTimeoutMs());
      }
      if (other.hasAutoParallel()) {
        mergeAutoParallel(other.getAutoParallel());
      }
      if (other.getFailOnOptimizerErrors() != false) {
        setFailOnOptimizerErrors(other.getFailOnOptimizerErrors());
      }
      if (other.hasScopedAllocatorOpts()) {
        mergeScopedAllocatorOpts(other.getScopedAllocatorOpts());
      }
      if (!other.optimizers_.isEmpty()) {
        if (optimizers_.isEmpty()) {
          optimizers_ = other.optimizers_;
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          ensureOptimizersIsMutable();
          optimizers_.addAll(other.optimizers_);
        }
        onChanged();
      }
      if (customOptimizersBuilder_ == null) {
        if (!other.customOptimizers_.isEmpty()) {
          if (customOptimizers_.isEmpty()) {
            customOptimizers_ = other.customOptimizers_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureCustomOptimizersIsMutable();
            customOptimizers_.addAll(other.customOptimizers_);
          }
          onChanged();
        }
      } else {
        if (!other.customOptimizers_.isEmpty()) {
          if (customOptimizersBuilder_.isEmpty()) {
            customOptimizersBuilder_.dispose();
            customOptimizersBuilder_ = null;
            customOptimizers_ = other.customOptimizers_;
            bitField0_ = (bitField0_ & ~0x00000002);
            customOptimizersBuilder_ = 
              com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                 getCustomOptimizersFieldBuilder() : null;
          } else {
            customOptimizersBuilder_.addAllMessages(other.customOptimizers_);
          }
        }
      }
      if (other.hasInterOptimizerVerifierConfig()) {
        mergeInterOptimizerVerifierConfig(other.getInterOptimizerVerifierConfig());
      }
      if (other.hasPostOptimizationVerifierConfig()) {
        mergePostOptimizationVerifierConfig(other.getPostOptimizationVerifierConfig());
      }
      this.mergeUnknownFields(other.getUnknownFields());
      onChanged();
      return this;
    }

    @java.lang.Override
    public final boolean isInitialized() {
      return true;
    }

    @java.lang.Override
    public Builder mergeFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      if (extensionRegistry == null) {
        throw new java.lang.NullPointerException();
      }
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            case 8: {
              layoutOptimizer_ = input.readEnum();

              break;
            } // case 8
            case 16: {
              disableModelPruning_ = input.readBool();

              break;
            } // case 16
            case 24: {
              constantFolding_ = input.readEnum();

              break;
            } // case 24
            case 32: {
              memoryOptimization_ = input.readEnum();

              break;
            } // case 32
            case 42: {
              input.readMessage(
                  getAutoParallelFieldBuilder().getBuilder(),
                  extensionRegistry);

              break;
            } // case 42
            case 50: {
              memoryOptimizerTargetNodeNameScope_ = input.readStringRequireUtf8();

              break;
            } // case 50
            case 56: {
              arithmeticOptimization_ = input.readEnum();

              break;
            } // case 56
            case 64: {
              dependencyOptimization_ = input.readEnum();

              break;
            } // case 64
            case 72: {
              loopOptimization_ = input.readEnum();

              break;
            } // case 72
            case 80: {
              functionOptimization_ = input.readEnum();

              break;
            } // case 80
            case 88: {
              debugStripper_ = input.readEnum();

              break;
            } // case 88
            case 96: {
              metaOptimizerIterations_ = input.readEnum();

              break;
            } // case 96
            case 104: {
              shapeOptimization_ = input.readEnum();

              break;
            } // case 104
            case 112: {
              remapping_ = input.readEnum();

              break;
            } // case 112
            case 120: {
              scopedAllocatorOptimization_ = input.readEnum();

              break;
            } // case 120
            case 130: {
              input.readMessage(
                  getScopedAllocatorOptsFieldBuilder().getBuilder(),
                  extensionRegistry);

              break;
            } // case 130
            case 136: {
              minGraphNodes_ = input.readInt32();

              break;
            } // case 136
            case 144: {
              pinToHostOptimization_ = input.readEnum();

              break;
            } // case 144
            case 152: {
              disableMetaOptimizer_ = input.readBool();

              break;
            } // case 152
            case 160: {
              metaOptimizerTimeoutMs_ = input.readInt64();

              break;
            } // case 160
            case 168: {
              failOnOptimizerErrors_ = input.readBool();

              break;
            } // case 168
            case 176: {
              implementationSelector_ = input.readEnum();

              break;
            } // case 176
            case 184: {
              autoMixedPrecision_ = input.readEnum();

              break;
            } // case 184
            case 192: {
              commonSubgraphElimination_ = input.readEnum();

              break;
            } // case 192
            case 200: {
              autoMixedPrecisionMkl_ = input.readEnum();

              break;
            } // case 200
            case 208: {
              experimentalDisableCompressedTensorOptimization_ = input.readBool();

              break;
            } // case 208
            case 216: {
              experimentalDisableFoldingQuantizationEmulation_ = input.readBool();

              break;
            } // case 216
            case 224: {
              usePluginOptimizers_ = input.readEnum();

              break;
            } // case 224
            case 232: {
              autoMixedPrecisionCpu_ = input.readEnum();

              break;
            } // case 232
            case 240: {
              experimentalConditionalCodeMotion_ = input.readEnum();

              break;
            } // case 240
            case 248: {
              autoMixedPrecisionOnednnBfloat16_ = input.readEnum();

              break;
            } // case 248
            case 400: {
              cpuLayoutConversion_ = input.readEnum();

              break;
            } // case 400
            case 802: {
              java.lang.String s = input.readStringRequireUtf8();
              ensureOptimizersIsMutable();
              optimizers_.add(s);
              break;
            } // case 802
            case 1602: {
              org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer m =
                  input.readMessage(
                      org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.parser(),
                      extensionRegistry);
              if (customOptimizersBuilder_ == null) {
                ensureCustomOptimizersIsMutable();
                customOptimizers_.add(m);
              } else {
                customOptimizersBuilder_.addMessage(m);
              }
              break;
            } // case 1602
            case 2402: {
              input.readMessage(
                  getInterOptimizerVerifierConfigFieldBuilder().getBuilder(),
                  extensionRegistry);

              break;
            } // case 2402
            case 2410: {
              input.readMessage(
                  getPostOptimizationVerifierConfigFieldBuilder().getBuilder(),
                  extensionRegistry);

              break;
            } // case 2410
            default: {
              if (!super.parseUnknownField(input, extensionRegistry, tag)) {
                done = true; // was an endgroup tag
              }
              break;
            } // default:
          } // switch (tag)
        } // while (!done)
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.unwrapIOException();
      } finally {
        onChanged();
      } // finally
      return this;
    }
    private int bitField0_;

    private int cpuLayoutConversion_ = 0;
    /**
     * <pre>
     * CPU Conversion settings between NHCW and NCHW.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.CpuLayout cpu_layout_conversion = 50;</code>
     * @return The enum numeric value on the wire for cpuLayoutConversion.
     */
    @java.lang.Override public int getCpuLayoutConversionValue() {
      return cpuLayoutConversion_;
    }
    /**
     * <pre>
     * CPU Conversion settings between NHCW and NCHW.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.CpuLayout cpu_layout_conversion = 50;</code>
     * @param value The enum numeric value on the wire for cpuLayoutConversion to set.
     * @return This builder for chaining.
     */
    public Builder setCpuLayoutConversionValue(int value) {
      
      cpuLayoutConversion_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * CPU Conversion settings between NHCW and NCHW.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.CpuLayout cpu_layout_conversion = 50;</code>
     * @return The cpuLayoutConversion.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.CpuLayout getCpuLayoutConversion() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.CpuLayout result = org.tensorflow.proto.framework.RewriterConfig.CpuLayout.valueOf(cpuLayoutConversion_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.CpuLayout.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * CPU Conversion settings between NHCW and NCHW.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.CpuLayout cpu_layout_conversion = 50;</code>
     * @param value The cpuLayoutConversion to set.
     * @return This builder for chaining.
     */
    public Builder setCpuLayoutConversion(org.tensorflow.proto.framework.RewriterConfig.CpuLayout value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      cpuLayoutConversion_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * CPU Conversion settings between NHCW and NCHW.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.CpuLayout cpu_layout_conversion = 50;</code>
     * @return This builder for chaining.
     */
    public Builder clearCpuLayoutConversion() {
      
      cpuLayoutConversion_ = 0;
      onChanged();
      return this;
    }

    private int layoutOptimizer_ = 0;
    /**
     * <pre>
     * Optimize tensor layouts (default is ON)
     * e.g. This will try to use NCHW layout on GPU which is faster.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle layout_optimizer = 1;</code>
     * @return The enum numeric value on the wire for layoutOptimizer.
     */
    @java.lang.Override public int getLayoutOptimizerValue() {
      return layoutOptimizer_;
    }
    /**
     * <pre>
     * Optimize tensor layouts (default is ON)
     * e.g. This will try to use NCHW layout on GPU which is faster.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle layout_optimizer = 1;</code>
     * @param value The enum numeric value on the wire for layoutOptimizer to set.
     * @return This builder for chaining.
     */
    public Builder setLayoutOptimizerValue(int value) {
      
      layoutOptimizer_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optimize tensor layouts (default is ON)
     * e.g. This will try to use NCHW layout on GPU which is faster.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle layout_optimizer = 1;</code>
     * @return The layoutOptimizer.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.Toggle getLayoutOptimizer() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(layoutOptimizer_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Optimize tensor layouts (default is ON)
     * e.g. This will try to use NCHW layout on GPU which is faster.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle layout_optimizer = 1;</code>
     * @param value The layoutOptimizer to set.
     * @return This builder for chaining.
     */
    public Builder setLayoutOptimizer(org.tensorflow.proto.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      layoutOptimizer_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optimize tensor layouts (default is ON)
     * e.g. This will try to use NCHW layout on GPU which is faster.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle layout_optimizer = 1;</code>
     * @return This builder for chaining.
     */
    public Builder clearLayoutOptimizer() {
      
      layoutOptimizer_ = 0;
      onChanged();
      return this;
    }

    private int constantFolding_ = 0;
    /**
     * <pre>
     * Fold constants (default is ON)
     * Statically infer the value of tensors when possible, and materialize the
     * result using constants.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
     * @return The enum numeric value on the wire for constantFolding.
     */
    @java.lang.Override public int getConstantFoldingValue() {
      return constantFolding_;
    }
    /**
     * <pre>
     * Fold constants (default is ON)
     * Statically infer the value of tensors when possible, and materialize the
     * result using constants.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
     * @param value The enum numeric value on the wire for constantFolding to set.
     * @return This builder for chaining.
     */
    public Builder setConstantFoldingValue(int value) {
      
      constantFolding_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Fold constants (default is ON)
     * Statically infer the value of tensors when possible, and materialize the
     * result using constants.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
     * @return The constantFolding.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.Toggle getConstantFolding() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(constantFolding_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Fold constants (default is ON)
     * Statically infer the value of tensors when possible, and materialize the
     * result using constants.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
     * @param value The constantFolding to set.
     * @return This builder for chaining.
     */
    public Builder setConstantFolding(org.tensorflow.proto.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      constantFolding_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Fold constants (default is ON)
     * Statically infer the value of tensors when possible, and materialize the
     * result using constants.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle constant_folding = 3;</code>
     * @return This builder for chaining.
     */
    public Builder clearConstantFolding() {
      
      constantFolding_ = 0;
      onChanged();
      return this;
    }

    private int shapeOptimization_ = 0;
    /**
     * <pre>
     * Shape optimizations (default is ON)
     * Simplify computations made on shapes.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle shape_optimization = 13;</code>
     * @return The enum numeric value on the wire for shapeOptimization.
     */
    @java.lang.Override public int getShapeOptimizationValue() {
      return shapeOptimization_;
    }
    /**
     * <pre>
     * Shape optimizations (default is ON)
     * Simplify computations made on shapes.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle shape_optimization = 13;</code>
     * @param value The enum numeric value on the wire for shapeOptimization to set.
     * @return This builder for chaining.
     */
    public Builder setShapeOptimizationValue(int value) {
      
      shapeOptimization_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Shape optimizations (default is ON)
     * Simplify computations made on shapes.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle shape_optimization = 13;</code>
     * @return The shapeOptimization.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.Toggle getShapeOptimization() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(shapeOptimization_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Shape optimizations (default is ON)
     * Simplify computations made on shapes.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle shape_optimization = 13;</code>
     * @param value The shapeOptimization to set.
     * @return This builder for chaining.
     */
    public Builder setShapeOptimization(org.tensorflow.proto.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      shapeOptimization_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Shape optimizations (default is ON)
     * Simplify computations made on shapes.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle shape_optimization = 13;</code>
     * @return This builder for chaining.
     */
    public Builder clearShapeOptimization() {
      
      shapeOptimization_ = 0;
      onChanged();
      return this;
    }

    private int remapping_ = 0;
    /**
     * <pre>
     * Remapping (default is ON)
     * Remap subgraphs onto more efficient implementations.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle remapping = 14;</code>
     * @return The enum numeric value on the wire for remapping.
     */
    @java.lang.Override public int getRemappingValue() {
      return remapping_;
    }
    /**
     * <pre>
     * Remapping (default is ON)
     * Remap subgraphs onto more efficient implementations.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle remapping = 14;</code>
     * @param value The enum numeric value on the wire for remapping to set.
     * @return This builder for chaining.
     */
    public Builder setRemappingValue(int value) {
      
      remapping_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Remapping (default is ON)
     * Remap subgraphs onto more efficient implementations.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle remapping = 14;</code>
     * @return The remapping.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.Toggle getRemapping() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(remapping_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Remapping (default is ON)
     * Remap subgraphs onto more efficient implementations.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle remapping = 14;</code>
     * @param value The remapping to set.
     * @return This builder for chaining.
     */
    public Builder setRemapping(org.tensorflow.proto.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      remapping_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Remapping (default is ON)
     * Remap subgraphs onto more efficient implementations.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle remapping = 14;</code>
     * @return This builder for chaining.
     */
    public Builder clearRemapping() {
      
      remapping_ = 0;
      onChanged();
      return this;
    }

    private int commonSubgraphElimination_ = 0;
    /**
     * <pre>
     * Common subgraph elimination (default is ON)
     * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle common_subgraph_elimination = 24;</code>
     * @return The enum numeric value on the wire for commonSubgraphElimination.
     */
    @java.lang.Override public int getCommonSubgraphEliminationValue() {
      return commonSubgraphElimination_;
    }
    /**
     * <pre>
     * Common subgraph elimination (default is ON)
     * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle common_subgraph_elimination = 24;</code>
     * @param value The enum numeric value on the wire for commonSubgraphElimination to set.
     * @return This builder for chaining.
     */
    public Builder setCommonSubgraphEliminationValue(int value) {
      
      commonSubgraphElimination_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Common subgraph elimination (default is ON)
     * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle common_subgraph_elimination = 24;</code>
     * @return The commonSubgraphElimination.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.Toggle getCommonSubgraphElimination() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(commonSubgraphElimination_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Common subgraph elimination (default is ON)
     * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle common_subgraph_elimination = 24;</code>
     * @param value The commonSubgraphElimination to set.
     * @return This builder for chaining.
     */
    public Builder setCommonSubgraphElimination(org.tensorflow.proto.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      commonSubgraphElimination_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Common subgraph elimination (default is ON)
     * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle common_subgraph_elimination = 24;</code>
     * @return This builder for chaining.
     */
    public Builder clearCommonSubgraphElimination() {
      
      commonSubgraphElimination_ = 0;
      onChanged();
      return this;
    }

    private int arithmeticOptimization_ = 0;
    /**
     * <pre>
     * Arithmetic optimizations (default is ON)
     * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
     * @return The enum numeric value on the wire for arithmeticOptimization.
     */
    @java.lang.Override public int getArithmeticOptimizationValue() {
      return arithmeticOptimization_;
    }
    /**
     * <pre>
     * Arithmetic optimizations (default is ON)
     * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
     * @param value The enum numeric value on the wire for arithmeticOptimization to set.
     * @return This builder for chaining.
     */
    public Builder setArithmeticOptimizationValue(int value) {
      
      arithmeticOptimization_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Arithmetic optimizations (default is ON)
     * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
     * @return The arithmeticOptimization.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.Toggle getArithmeticOptimization() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(arithmeticOptimization_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Arithmetic optimizations (default is ON)
     * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
     * @param value The arithmeticOptimization to set.
     * @return This builder for chaining.
     */
    public Builder setArithmeticOptimization(org.tensorflow.proto.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      arithmeticOptimization_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Arithmetic optimizations (default is ON)
     * e.g. Simplify arithmetic ops; merge ops with same value (like constants).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle arithmetic_optimization = 7;</code>
     * @return This builder for chaining.
     */
    public Builder clearArithmeticOptimization() {
      
      arithmeticOptimization_ = 0;
      onChanged();
      return this;
    }

    private int dependencyOptimization_ = 0;
    /**
     * <pre>
     * Control dependency optimizations (default is ON).
     * Remove redundant control dependencies, which may enable other optimization.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle dependency_optimization = 8;</code>
     * @return The enum numeric value on the wire for dependencyOptimization.
     */
    @java.lang.Override public int getDependencyOptimizationValue() {
      return dependencyOptimization_;
    }
    /**
     * <pre>
     * Control dependency optimizations (default is ON).
     * Remove redundant control dependencies, which may enable other optimization.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle dependency_optimization = 8;</code>
     * @param value The enum numeric value on the wire for dependencyOptimization to set.
     * @return This builder for chaining.
     */
    public Builder setDependencyOptimizationValue(int value) {
      
      dependencyOptimization_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Control dependency optimizations (default is ON).
     * Remove redundant control dependencies, which may enable other optimization.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle dependency_optimization = 8;</code>
     * @return The dependencyOptimization.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.Toggle getDependencyOptimization() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(dependencyOptimization_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Control dependency optimizations (default is ON).
     * Remove redundant control dependencies, which may enable other optimization.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle dependency_optimization = 8;</code>
     * @param value The dependencyOptimization to set.
     * @return This builder for chaining.
     */
    public Builder setDependencyOptimization(org.tensorflow.proto.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      dependencyOptimization_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Control dependency optimizations (default is ON).
     * Remove redundant control dependencies, which may enable other optimization.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle dependency_optimization = 8;</code>
     * @return This builder for chaining.
     */
    public Builder clearDependencyOptimization() {
      
      dependencyOptimization_ = 0;
      onChanged();
      return this;
    }

    private int loopOptimization_ = 0;
    /**
     * <pre>
     * Loop optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle loop_optimization = 9;</code>
     * @return The enum numeric value on the wire for loopOptimization.
     */
    @java.lang.Override public int getLoopOptimizationValue() {
      return loopOptimization_;
    }
    /**
     * <pre>
     * Loop optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle loop_optimization = 9;</code>
     * @param value The enum numeric value on the wire for loopOptimization to set.
     * @return This builder for chaining.
     */
    public Builder setLoopOptimizationValue(int value) {
      
      loopOptimization_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Loop optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle loop_optimization = 9;</code>
     * @return The loopOptimization.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.Toggle getLoopOptimization() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(loopOptimization_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Loop optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle loop_optimization = 9;</code>
     * @param value The loopOptimization to set.
     * @return This builder for chaining.
     */
    public Builder setLoopOptimization(org.tensorflow.proto.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      loopOptimization_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Loop optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle loop_optimization = 9;</code>
     * @return This builder for chaining.
     */
    public Builder clearLoopOptimization() {
      
      loopOptimization_ = 0;
      onChanged();
      return this;
    }

    private int functionOptimization_ = 0;
    /**
     * <pre>
     * Function optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle function_optimization = 10;</code>
     * @return The enum numeric value on the wire for functionOptimization.
     */
    @java.lang.Override public int getFunctionOptimizationValue() {
      return functionOptimization_;
    }
    /**
     * <pre>
     * Function optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle function_optimization = 10;</code>
     * @param value The enum numeric value on the wire for functionOptimization to set.
     * @return This builder for chaining.
     */
    public Builder setFunctionOptimizationValue(int value) {
      
      functionOptimization_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Function optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle function_optimization = 10;</code>
     * @return The functionOptimization.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.Toggle getFunctionOptimization() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(functionOptimization_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Function optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle function_optimization = 10;</code>
     * @param value The functionOptimization to set.
     * @return This builder for chaining.
     */
    public Builder setFunctionOptimization(org.tensorflow.proto.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      functionOptimization_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Function optimizations (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle function_optimization = 10;</code>
     * @return This builder for chaining.
     */
    public Builder clearFunctionOptimization() {
      
      functionOptimization_ = 0;
      onChanged();
      return this;
    }

    private int debugStripper_ = 0;
    /**
     * <pre>
     * Strips debug-related nodes from the graph (off by default).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle debug_stripper = 11;</code>
     * @return The enum numeric value on the wire for debugStripper.
     */
    @java.lang.Override public int getDebugStripperValue() {
      return debugStripper_;
    }
    /**
     * <pre>
     * Strips debug-related nodes from the graph (off by default).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle debug_stripper = 11;</code>
     * @param value The enum numeric value on the wire for debugStripper to set.
     * @return This builder for chaining.
     */
    public Builder setDebugStripperValue(int value) {
      
      debugStripper_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Strips debug-related nodes from the graph (off by default).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle debug_stripper = 11;</code>
     * @return The debugStripper.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.Toggle getDebugStripper() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(debugStripper_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Strips debug-related nodes from the graph (off by default).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle debug_stripper = 11;</code>
     * @param value The debugStripper to set.
     * @return This builder for chaining.
     */
    public Builder setDebugStripper(org.tensorflow.proto.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      debugStripper_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Strips debug-related nodes from the graph (off by default).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle debug_stripper = 11;</code>
     * @return This builder for chaining.
     */
    public Builder clearDebugStripper() {
      
      debugStripper_ = 0;
      onChanged();
      return this;
    }

    private boolean disableModelPruning_ ;
    /**
     * <pre>
     * If true, don't remove unnecessary ops from the graph
     * </pre>
     *
     * <code>bool disable_model_pruning = 2;</code>
     * @return The disableModelPruning.
     */
    @java.lang.Override
    public boolean getDisableModelPruning() {
      return disableModelPruning_;
    }
    /**
     * <pre>
     * If true, don't remove unnecessary ops from the graph
     * </pre>
     *
     * <code>bool disable_model_pruning = 2;</code>
     * @param value The disableModelPruning to set.
     * @return This builder for chaining.
     */
    public Builder setDisableModelPruning(boolean value) {
      
      disableModelPruning_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * If true, don't remove unnecessary ops from the graph
     * </pre>
     *
     * <code>bool disable_model_pruning = 2;</code>
     * @return This builder for chaining.
     */
    public Builder clearDisableModelPruning() {
      
      disableModelPruning_ = false;
      onChanged();
      return this;
    }

    private int scopedAllocatorOptimization_ = 0;
    /**
     * <pre>
     * Try to allocate some independent Op outputs contiguously in order to
     * merge or eliminate downstream Ops (off by default).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle scoped_allocator_optimization = 15;</code>
     * @return The enum numeric value on the wire for scopedAllocatorOptimization.
     */
    @java.lang.Override public int getScopedAllocatorOptimizationValue() {
      return scopedAllocatorOptimization_;
    }
    /**
     * <pre>
     * Try to allocate some independent Op outputs contiguously in order to
     * merge or eliminate downstream Ops (off by default).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle scoped_allocator_optimization = 15;</code>
     * @param value The enum numeric value on the wire for scopedAllocatorOptimization to set.
     * @return This builder for chaining.
     */
    public Builder setScopedAllocatorOptimizationValue(int value) {
      
      scopedAllocatorOptimization_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Try to allocate some independent Op outputs contiguously in order to
     * merge or eliminate downstream Ops (off by default).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle scoped_allocator_optimization = 15;</code>
     * @return The scopedAllocatorOptimization.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.Toggle getScopedAllocatorOptimization() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(scopedAllocatorOptimization_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Try to allocate some independent Op outputs contiguously in order to
     * merge or eliminate downstream Ops (off by default).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle scoped_allocator_optimization = 15;</code>
     * @param value The scopedAllocatorOptimization to set.
     * @return This builder for chaining.
     */
    public Builder setScopedAllocatorOptimization(org.tensorflow.proto.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      scopedAllocatorOptimization_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Try to allocate some independent Op outputs contiguously in order to
     * merge or eliminate downstream Ops (off by default).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle scoped_allocator_optimization = 15;</code>
     * @return This builder for chaining.
     */
    public Builder clearScopedAllocatorOptimization() {
      
      scopedAllocatorOptimization_ = 0;
      onChanged();
      return this;
    }

    private int pinToHostOptimization_ = 0;
    /**
     * <pre>
     * Force small ops onto the CPU (default is OFF).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle pin_to_host_optimization = 18;</code>
     * @return The enum numeric value on the wire for pinToHostOptimization.
     */
    @java.lang.Override public int getPinToHostOptimizationValue() {
      return pinToHostOptimization_;
    }
    /**
     * <pre>
     * Force small ops onto the CPU (default is OFF).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle pin_to_host_optimization = 18;</code>
     * @param value The enum numeric value on the wire for pinToHostOptimization to set.
     * @return This builder for chaining.
     */
    public Builder setPinToHostOptimizationValue(int value) {
      
      pinToHostOptimization_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Force small ops onto the CPU (default is OFF).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle pin_to_host_optimization = 18;</code>
     * @return The pinToHostOptimization.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.Toggle getPinToHostOptimization() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(pinToHostOptimization_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Force small ops onto the CPU (default is OFF).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle pin_to_host_optimization = 18;</code>
     * @param value The pinToHostOptimization to set.
     * @return This builder for chaining.
     */
    public Builder setPinToHostOptimization(org.tensorflow.proto.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      pinToHostOptimization_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Force small ops onto the CPU (default is OFF).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle pin_to_host_optimization = 18;</code>
     * @return This builder for chaining.
     */
    public Builder clearPinToHostOptimization() {
      
      pinToHostOptimization_ = 0;
      onChanged();
      return this;
    }

    private int implementationSelector_ = 0;
    /**
     * <pre>
     * Enable the swap of kernel implementations based on the device placement
     * (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle implementation_selector = 22;</code>
     * @return The enum numeric value on the wire for implementationSelector.
     */
    @java.lang.Override public int getImplementationSelectorValue() {
      return implementationSelector_;
    }
    /**
     * <pre>
     * Enable the swap of kernel implementations based on the device placement
     * (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle implementation_selector = 22;</code>
     * @param value The enum numeric value on the wire for implementationSelector to set.
     * @return This builder for chaining.
     */
    public Builder setImplementationSelectorValue(int value) {
      
      implementationSelector_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Enable the swap of kernel implementations based on the device placement
     * (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle implementation_selector = 22;</code>
     * @return The implementationSelector.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.Toggle getImplementationSelector() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(implementationSelector_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Enable the swap of kernel implementations based on the device placement
     * (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle implementation_selector = 22;</code>
     * @param value The implementationSelector to set.
     * @return This builder for chaining.
     */
    public Builder setImplementationSelector(org.tensorflow.proto.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      implementationSelector_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Enable the swap of kernel implementations based on the device placement
     * (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle implementation_selector = 22;</code>
     * @return This builder for chaining.
     */
    public Builder clearImplementationSelector() {
      
      implementationSelector_ = 0;
      onChanged();
      return this;
    }

    private int autoMixedPrecision_ = 0;
    /**
     * <pre>
     * Optimize data types for CUDA (default is OFF).
     * This will try to use float16 on GPU which is faster.
     * Note that this can change the numerical stability of the graph and may
     * require the use of loss scaling to maintain model convergence.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision = 23;</code>
     * @return The enum numeric value on the wire for autoMixedPrecision.
     */
    @java.lang.Override public int getAutoMixedPrecisionValue() {
      return autoMixedPrecision_;
    }
    /**
     * <pre>
     * Optimize data types for CUDA (default is OFF).
     * This will try to use float16 on GPU which is faster.
     * Note that this can change the numerical stability of the graph and may
     * require the use of loss scaling to maintain model convergence.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision = 23;</code>
     * @param value The enum numeric value on the wire for autoMixedPrecision to set.
     * @return This builder for chaining.
     */
    public Builder setAutoMixedPrecisionValue(int value) {
      
      autoMixedPrecision_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optimize data types for CUDA (default is OFF).
     * This will try to use float16 on GPU which is faster.
     * Note that this can change the numerical stability of the graph and may
     * require the use of loss scaling to maintain model convergence.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision = 23;</code>
     * @return The autoMixedPrecision.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.Toggle getAutoMixedPrecision() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(autoMixedPrecision_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Optimize data types for CUDA (default is OFF).
     * This will try to use float16 on GPU which is faster.
     * Note that this can change the numerical stability of the graph and may
     * require the use of loss scaling to maintain model convergence.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision = 23;</code>
     * @param value The autoMixedPrecision to set.
     * @return This builder for chaining.
     */
    public Builder setAutoMixedPrecision(org.tensorflow.proto.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      autoMixedPrecision_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optimize data types for CUDA (default is OFF).
     * This will try to use float16 on GPU which is faster.
     * Note that this can change the numerical stability of the graph and may
     * require the use of loss scaling to maintain model convergence.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision = 23;</code>
     * @return This builder for chaining.
     */
    public Builder clearAutoMixedPrecision() {
      
      autoMixedPrecision_ = 0;
      onChanged();
      return this;
    }

    private int autoMixedPrecisionMkl_ = 0;
    /**
     * <pre>
     * Optimize data types for oneDNN (default is OFF).
     * This will try to use bfloat16 on CPUs, which is faster.
     * Note that this can change the numerical stability of the graph.
     * Note: this is deprecated.
     * It is replaced by auto_mixed_precision_onednn_bfloat16
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_mkl = 25;</code>
     * @return The enum numeric value on the wire for autoMixedPrecisionMkl.
     */
    @java.lang.Override public int getAutoMixedPrecisionMklValue() {
      return autoMixedPrecisionMkl_;
    }
    /**
     * <pre>
     * Optimize data types for oneDNN (default is OFF).
     * This will try to use bfloat16 on CPUs, which is faster.
     * Note that this can change the numerical stability of the graph.
     * Note: this is deprecated.
     * It is replaced by auto_mixed_precision_onednn_bfloat16
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_mkl = 25;</code>
     * @param value The enum numeric value on the wire for autoMixedPrecisionMkl to set.
     * @return This builder for chaining.
     */
    public Builder setAutoMixedPrecisionMklValue(int value) {
      
      autoMixedPrecisionMkl_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optimize data types for oneDNN (default is OFF).
     * This will try to use bfloat16 on CPUs, which is faster.
     * Note that this can change the numerical stability of the graph.
     * Note: this is deprecated.
     * It is replaced by auto_mixed_precision_onednn_bfloat16
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_mkl = 25;</code>
     * @return The autoMixedPrecisionMkl.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.Toggle getAutoMixedPrecisionMkl() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(autoMixedPrecisionMkl_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Optimize data types for oneDNN (default is OFF).
     * This will try to use bfloat16 on CPUs, which is faster.
     * Note that this can change the numerical stability of the graph.
     * Note: this is deprecated.
     * It is replaced by auto_mixed_precision_onednn_bfloat16
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_mkl = 25;</code>
     * @param value The autoMixedPrecisionMkl to set.
     * @return This builder for chaining.
     */
    public Builder setAutoMixedPrecisionMkl(org.tensorflow.proto.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      autoMixedPrecisionMkl_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optimize data types for oneDNN (default is OFF).
     * This will try to use bfloat16 on CPUs, which is faster.
     * Note that this can change the numerical stability of the graph.
     * Note: this is deprecated.
     * It is replaced by auto_mixed_precision_onednn_bfloat16
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_mkl = 25;</code>
     * @return This builder for chaining.
     */
    public Builder clearAutoMixedPrecisionMkl() {
      
      autoMixedPrecisionMkl_ = 0;
      onChanged();
      return this;
    }

    private int autoMixedPrecisionOnednnBfloat16_ = 0;
    /**
     * <pre>
     * Optimize data types for oneDNN (default is OFF).
     * This will try to use bfloat16 on CPUs, which is faster.
     * Note that this can change the numerical stability of the graph.
     * Note: this is equivalent to the deprecated option auto_mixed_precision_mkl
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_onednn_bfloat16 = 31;</code>
     * @return The enum numeric value on the wire for autoMixedPrecisionOnednnBfloat16.
     */
    @java.lang.Override public int getAutoMixedPrecisionOnednnBfloat16Value() {
      return autoMixedPrecisionOnednnBfloat16_;
    }
    /**
     * <pre>
     * Optimize data types for oneDNN (default is OFF).
     * This will try to use bfloat16 on CPUs, which is faster.
     * Note that this can change the numerical stability of the graph.
     * Note: this is equivalent to the deprecated option auto_mixed_precision_mkl
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_onednn_bfloat16 = 31;</code>
     * @param value The enum numeric value on the wire for autoMixedPrecisionOnednnBfloat16 to set.
     * @return This builder for chaining.
     */
    public Builder setAutoMixedPrecisionOnednnBfloat16Value(int value) {
      
      autoMixedPrecisionOnednnBfloat16_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optimize data types for oneDNN (default is OFF).
     * This will try to use bfloat16 on CPUs, which is faster.
     * Note that this can change the numerical stability of the graph.
     * Note: this is equivalent to the deprecated option auto_mixed_precision_mkl
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_onednn_bfloat16 = 31;</code>
     * @return The autoMixedPrecisionOnednnBfloat16.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.Toggle getAutoMixedPrecisionOnednnBfloat16() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(autoMixedPrecisionOnednnBfloat16_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Optimize data types for oneDNN (default is OFF).
     * This will try to use bfloat16 on CPUs, which is faster.
     * Note that this can change the numerical stability of the graph.
     * Note: this is equivalent to the deprecated option auto_mixed_precision_mkl
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_onednn_bfloat16 = 31;</code>
     * @param value The autoMixedPrecisionOnednnBfloat16 to set.
     * @return This builder for chaining.
     */
    public Builder setAutoMixedPrecisionOnednnBfloat16(org.tensorflow.proto.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      autoMixedPrecisionOnednnBfloat16_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optimize data types for oneDNN (default is OFF).
     * This will try to use bfloat16 on CPUs, which is faster.
     * Note that this can change the numerical stability of the graph.
     * Note: this is equivalent to the deprecated option auto_mixed_precision_mkl
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_onednn_bfloat16 = 31;</code>
     * @return This builder for chaining.
     */
    public Builder clearAutoMixedPrecisionOnednnBfloat16() {
      
      autoMixedPrecisionOnednnBfloat16_ = 0;
      onChanged();
      return this;
    }

    private int autoMixedPrecisionCpu_ = 0;
    /**
     * <pre>
     * Emulate a model using data type float16 on CPU (default is OFF).
     * This will try to emulate the float16 inputs and outputs of an operator
     * on CPU to have better correlation with float16 on GPU; however the
     * computation in the operator is based on float32.
     * Note that this can change the numerical stability of the graph.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_cpu = 29;</code>
     * @return The enum numeric value on the wire for autoMixedPrecisionCpu.
     */
    @java.lang.Override public int getAutoMixedPrecisionCpuValue() {
      return autoMixedPrecisionCpu_;
    }
    /**
     * <pre>
     * Emulate a model using data type float16 on CPU (default is OFF).
     * This will try to emulate the float16 inputs and outputs of an operator
     * on CPU to have better correlation with float16 on GPU; however the
     * computation in the operator is based on float32.
     * Note that this can change the numerical stability of the graph.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_cpu = 29;</code>
     * @param value The enum numeric value on the wire for autoMixedPrecisionCpu to set.
     * @return This builder for chaining.
     */
    public Builder setAutoMixedPrecisionCpuValue(int value) {
      
      autoMixedPrecisionCpu_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Emulate a model using data type float16 on CPU (default is OFF).
     * This will try to emulate the float16 inputs and outputs of an operator
     * on CPU to have better correlation with float16 on GPU; however the
     * computation in the operator is based on float32.
     * Note that this can change the numerical stability of the graph.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_cpu = 29;</code>
     * @return The autoMixedPrecisionCpu.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.Toggle getAutoMixedPrecisionCpu() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(autoMixedPrecisionCpu_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Emulate a model using data type float16 on CPU (default is OFF).
     * This will try to emulate the float16 inputs and outputs of an operator
     * on CPU to have better correlation with float16 on GPU; however the
     * computation in the operator is based on float32.
     * Note that this can change the numerical stability of the graph.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_cpu = 29;</code>
     * @param value The autoMixedPrecisionCpu to set.
     * @return This builder for chaining.
     */
    public Builder setAutoMixedPrecisionCpu(org.tensorflow.proto.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      autoMixedPrecisionCpu_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Emulate a model using data type float16 on CPU (default is OFF).
     * This will try to emulate the float16 inputs and outputs of an operator
     * on CPU to have better correlation with float16 on GPU; however the
     * computation in the operator is based on float32.
     * Note that this can change the numerical stability of the graph.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle auto_mixed_precision_cpu = 29;</code>
     * @return This builder for chaining.
     */
    public Builder clearAutoMixedPrecisionCpu() {
      
      autoMixedPrecisionCpu_ = 0;
      onChanged();
      return this;
    }

    private boolean disableMetaOptimizer_ ;
    /**
     * <pre>
     * Disable the entire meta optimizer (off by default).
     * </pre>
     *
     * <code>bool disable_meta_optimizer = 19;</code>
     * @return The disableMetaOptimizer.
     */
    @java.lang.Override
    public boolean getDisableMetaOptimizer() {
      return disableMetaOptimizer_;
    }
    /**
     * <pre>
     * Disable the entire meta optimizer (off by default).
     * </pre>
     *
     * <code>bool disable_meta_optimizer = 19;</code>
     * @param value The disableMetaOptimizer to set.
     * @return This builder for chaining.
     */
    public Builder setDisableMetaOptimizer(boolean value) {
      
      disableMetaOptimizer_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Disable the entire meta optimizer (off by default).
     * </pre>
     *
     * <code>bool disable_meta_optimizer = 19;</code>
     * @return This builder for chaining.
     */
    public Builder clearDisableMetaOptimizer() {
      
      disableMetaOptimizer_ = false;
      onChanged();
      return this;
    }

    private int usePluginOptimizers_ = 0;
    /**
     * <pre>
     * Optimizers registered by plugin (default is ON)
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle use_plugin_optimizers = 28;</code>
     * @return The enum numeric value on the wire for usePluginOptimizers.
     */
    @java.lang.Override public int getUsePluginOptimizersValue() {
      return usePluginOptimizers_;
    }
    /**
     * <pre>
     * Optimizers registered by plugin (default is ON)
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle use_plugin_optimizers = 28;</code>
     * @param value The enum numeric value on the wire for usePluginOptimizers to set.
     * @return This builder for chaining.
     */
    public Builder setUsePluginOptimizersValue(int value) {
      
      usePluginOptimizers_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optimizers registered by plugin (default is ON)
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle use_plugin_optimizers = 28;</code>
     * @return The usePluginOptimizers.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.Toggle getUsePluginOptimizers() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(usePluginOptimizers_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Optimizers registered by plugin (default is ON)
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle use_plugin_optimizers = 28;</code>
     * @param value The usePluginOptimizers to set.
     * @return This builder for chaining.
     */
    public Builder setUsePluginOptimizers(org.tensorflow.proto.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      usePluginOptimizers_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Optimizers registered by plugin (default is ON)
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle use_plugin_optimizers = 28;</code>
     * @return This builder for chaining.
     */
    public Builder clearUsePluginOptimizers() {
      
      usePluginOptimizers_ = 0;
      onChanged();
      return this;
    }

    private int experimentalConditionalCodeMotion_ = 0;
    /**
     * <pre>
     * Conditional code motion (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle experimental_conditional_code_motion = 30;</code>
     * @return The enum numeric value on the wire for experimentalConditionalCodeMotion.
     */
    @java.lang.Override public int getExperimentalConditionalCodeMotionValue() {
      return experimentalConditionalCodeMotion_;
    }
    /**
     * <pre>
     * Conditional code motion (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle experimental_conditional_code_motion = 30;</code>
     * @param value The enum numeric value on the wire for experimentalConditionalCodeMotion to set.
     * @return This builder for chaining.
     */
    public Builder setExperimentalConditionalCodeMotionValue(int value) {
      
      experimentalConditionalCodeMotion_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Conditional code motion (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle experimental_conditional_code_motion = 30;</code>
     * @return The experimentalConditionalCodeMotion.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.Toggle getExperimentalConditionalCodeMotion() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.Toggle result = org.tensorflow.proto.framework.RewriterConfig.Toggle.valueOf(experimentalConditionalCodeMotion_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.Toggle.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Conditional code motion (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle experimental_conditional_code_motion = 30;</code>
     * @param value The experimentalConditionalCodeMotion to set.
     * @return This builder for chaining.
     */
    public Builder setExperimentalConditionalCodeMotion(org.tensorflow.proto.framework.RewriterConfig.Toggle value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      experimentalConditionalCodeMotion_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Conditional code motion (default is ON).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.Toggle experimental_conditional_code_motion = 30;</code>
     * @return This builder for chaining.
     */
    public Builder clearExperimentalConditionalCodeMotion() {
      
      experimentalConditionalCodeMotion_ = 0;
      onChanged();
      return this;
    }

    private int metaOptimizerIterations_ = 0;
    /**
     * <pre>
     * Controls how many times we run the optimizers in meta optimizer (default
     * is once).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;</code>
     * @return The enum numeric value on the wire for metaOptimizerIterations.
     */
    @java.lang.Override public int getMetaOptimizerIterationsValue() {
      return metaOptimizerIterations_;
    }
    /**
     * <pre>
     * Controls how many times we run the optimizers in meta optimizer (default
     * is once).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;</code>
     * @param value The enum numeric value on the wire for metaOptimizerIterations to set.
     * @return This builder for chaining.
     */
    public Builder setMetaOptimizerIterationsValue(int value) {
      
      metaOptimizerIterations_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Controls how many times we run the optimizers in meta optimizer (default
     * is once).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;</code>
     * @return The metaOptimizerIterations.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.NumIterationsType getMetaOptimizerIterations() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.NumIterationsType result = org.tensorflow.proto.framework.RewriterConfig.NumIterationsType.valueOf(metaOptimizerIterations_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.NumIterationsType.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Controls how many times we run the optimizers in meta optimizer (default
     * is once).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;</code>
     * @param value The metaOptimizerIterations to set.
     * @return This builder for chaining.
     */
    public Builder setMetaOptimizerIterations(org.tensorflow.proto.framework.RewriterConfig.NumIterationsType value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      metaOptimizerIterations_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Controls how many times we run the optimizers in meta optimizer (default
     * is once).
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.NumIterationsType meta_optimizer_iterations = 12;</code>
     * @return This builder for chaining.
     */
    public Builder clearMetaOptimizerIterations() {
      
      metaOptimizerIterations_ = 0;
      onChanged();
      return this;
    }

    private int minGraphNodes_ ;
    /**
     * <pre>
     * The minimum number of nodes in a graph to optimizer. For smaller graphs,
     * optimization is skipped.
     * 0 means the system picks an appropriate number.
     * &lt; 0 means do not skip optimization.
     * </pre>
     *
     * <code>int32 min_graph_nodes = 17;</code>
     * @return The minGraphNodes.
     */
    @java.lang.Override
    public int getMinGraphNodes() {
      return minGraphNodes_;
    }
    /**
     * <pre>
     * The minimum number of nodes in a graph to optimizer. For smaller graphs,
     * optimization is skipped.
     * 0 means the system picks an appropriate number.
     * &lt; 0 means do not skip optimization.
     * </pre>
     *
     * <code>int32 min_graph_nodes = 17;</code>
     * @param value The minGraphNodes to set.
     * @return This builder for chaining.
     */
    public Builder setMinGraphNodes(int value) {
      
      minGraphNodes_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * The minimum number of nodes in a graph to optimizer. For smaller graphs,
     * optimization is skipped.
     * 0 means the system picks an appropriate number.
     * &lt; 0 means do not skip optimization.
     * </pre>
     *
     * <code>int32 min_graph_nodes = 17;</code>
     * @return This builder for chaining.
     */
    public Builder clearMinGraphNodes() {
      
      minGraphNodes_ = 0;
      onChanged();
      return this;
    }

    private boolean experimentalDisableCompressedTensorOptimization_ ;
    /**
     * <pre>
     * Disable optimizations that assume compressed tensors. Note that this flag
     * is experimental and may be removed in the future.
     * </pre>
     *
     * <code>bool experimental_disable_compressed_tensor_optimization = 26;</code>
     * @return The experimentalDisableCompressedTensorOptimization.
     */
    @java.lang.Override
    public boolean getExperimentalDisableCompressedTensorOptimization() {
      return experimentalDisableCompressedTensorOptimization_;
    }
    /**
     * <pre>
     * Disable optimizations that assume compressed tensors. Note that this flag
     * is experimental and may be removed in the future.
     * </pre>
     *
     * <code>bool experimental_disable_compressed_tensor_optimization = 26;</code>
     * @param value The experimentalDisableCompressedTensorOptimization to set.
     * @return This builder for chaining.
     */
    public Builder setExperimentalDisableCompressedTensorOptimization(boolean value) {
      
      experimentalDisableCompressedTensorOptimization_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Disable optimizations that assume compressed tensors. Note that this flag
     * is experimental and may be removed in the future.
     * </pre>
     *
     * <code>bool experimental_disable_compressed_tensor_optimization = 26;</code>
     * @return This builder for chaining.
     */
    public Builder clearExperimentalDisableCompressedTensorOptimization() {
      
      experimentalDisableCompressedTensorOptimization_ = false;
      onChanged();
      return this;
    }

    private boolean experimentalDisableFoldingQuantizationEmulation_ ;
    /**
     * <pre>
     * Disable folding quantization emulation ops such as FakeQuantWithMinMax* and
     * QuantizeAndDequantize*. Some compilers (e.g. the TF-to-tflite converter)
     * have to extract quantization configs (e.g. min/max range, number of bits,
     * and per-channel) from the quantization emulation ops. Note that this flag
     * is experimental and may be removed in the future. See b/174138564 for more
     * details.
     * </pre>
     *
     * <code>bool experimental_disable_folding_quantization_emulation = 27;</code>
     * @return The experimentalDisableFoldingQuantizationEmulation.
     */
    @java.lang.Override
    public boolean getExperimentalDisableFoldingQuantizationEmulation() {
      return experimentalDisableFoldingQuantizationEmulation_;
    }
    /**
     * <pre>
     * Disable folding quantization emulation ops such as FakeQuantWithMinMax* and
     * QuantizeAndDequantize*. Some compilers (e.g. the TF-to-tflite converter)
     * have to extract quantization configs (e.g. min/max range, number of bits,
     * and per-channel) from the quantization emulation ops. Note that this flag
     * is experimental and may be removed in the future. See b/174138564 for more
     * details.
     * </pre>
     *
     * <code>bool experimental_disable_folding_quantization_emulation = 27;</code>
     * @param value The experimentalDisableFoldingQuantizationEmulation to set.
     * @return This builder for chaining.
     */
    public Builder setExperimentalDisableFoldingQuantizationEmulation(boolean value) {
      
      experimentalDisableFoldingQuantizationEmulation_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Disable folding quantization emulation ops such as FakeQuantWithMinMax* and
     * QuantizeAndDequantize*. Some compilers (e.g. the TF-to-tflite converter)
     * have to extract quantization configs (e.g. min/max range, number of bits,
     * and per-channel) from the quantization emulation ops. Note that this flag
     * is experimental and may be removed in the future. See b/174138564 for more
     * details.
     * </pre>
     *
     * <code>bool experimental_disable_folding_quantization_emulation = 27;</code>
     * @return This builder for chaining.
     */
    public Builder clearExperimentalDisableFoldingQuantizationEmulation() {
      
      experimentalDisableFoldingQuantizationEmulation_ = false;
      onChanged();
      return this;
    }

    private int memoryOptimization_ = 0;
    /**
     * <pre>
     * Configures memory optimization passes through the meta-optimizer. Has no
     * effect on manually requested memory optimization passes in the optimizers
     * field.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
     * @return The enum numeric value on the wire for memoryOptimization.
     */
    @java.lang.Override public int getMemoryOptimizationValue() {
      return memoryOptimization_;
    }
    /**
     * <pre>
     * Configures memory optimization passes through the meta-optimizer. Has no
     * effect on manually requested memory optimization passes in the optimizers
     * field.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
     * @param value The enum numeric value on the wire for memoryOptimization to set.
     * @return This builder for chaining.
     */
    public Builder setMemoryOptimizationValue(int value) {
      
      memoryOptimization_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Configures memory optimization passes through the meta-optimizer. Has no
     * effect on manually requested memory optimization passes in the optimizers
     * field.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
     * @return The memoryOptimization.
     */
    @java.lang.Override
    public org.tensorflow.proto.framework.RewriterConfig.MemOptType getMemoryOptimization() {
      @SuppressWarnings("deprecation")
      org.tensorflow.proto.framework.RewriterConfig.MemOptType result = org.tensorflow.proto.framework.RewriterConfig.MemOptType.valueOf(memoryOptimization_);
      return result == null ? org.tensorflow.proto.framework.RewriterConfig.MemOptType.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * Configures memory optimization passes through the meta-optimizer. Has no
     * effect on manually requested memory optimization passes in the optimizers
     * field.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
     * @param value The memoryOptimization to set.
     * @return This builder for chaining.
     */
    public Builder setMemoryOptimization(org.tensorflow.proto.framework.RewriterConfig.MemOptType value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      memoryOptimization_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Configures memory optimization passes through the meta-optimizer. Has no
     * effect on manually requested memory optimization passes in the optimizers
     * field.
     * </pre>
     *
     * <code>.tensorflow.RewriterConfig.MemOptType memory_optimization = 4;</code>
     * @return This builder for chaining.
     */
    public Builder clearMemoryOptimization() {
      
      memoryOptimization_ = 0;
      onChanged();
      return this;
    }

    private java.lang.Object memoryOptimizerTargetNodeNameScope_ = "";
    /**
     * <pre>
     * A node name scope for node names which are valid outputs of recomputations.
     * Inputs to nodes that match this scope may be recomputed (subject either to
     * manual annotation of those input nodes or to manual annotation and
     * heuristics depending on memory_optimization), but the nodes themselves will
     * not be recomputed. This matches any sub-scopes as well, meaning the scope
     * can appear not just as a top-level scope. For example, if the value is
     * "gradients/", the default, it will match node name "gradients/foo",
     * "foo/gradients/bar", but not "foo_gradients/"
     * </pre>
     *
     * <code>string memory_optimizer_target_node_name_scope = 6;</code>
     * @return The memoryOptimizerTargetNodeNameScope.
     */
    public java.lang.String getMemoryOptimizerTargetNodeNameScope() {
      java.lang.Object ref = memoryOptimizerTargetNodeNameScope_;
      if (!(ref instanceof java.lang.String)) {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        memoryOptimizerTargetNodeNameScope_ = s;
        return s;
      } else {
        return (java.lang.String) ref;
      }
    }
    /**
     * <pre>
     * A node name scope for node names which are valid outputs of recomputations.
     * Inputs to nodes that match this scope may be recomputed (subject either to
     * manual annotation of those input nodes or to manual annotation and
     * heuristics depending on memory_optimization), but the nodes themselves will
     * not be recomputed. This matches any sub-scopes as well, meaning the scope
     * can appear not just as a top-level scope. For example, if the value is
     * "gradients/", the default, it will match node name "gradients/foo",
     * "foo/gradients/bar", but not "foo_gradients/"
     * </pre>
     *
     * <code>string memory_optimizer_target_node_name_scope = 6;</code>
     * @return The bytes for memoryOptimizerTargetNodeNameScope.
     */
    public com.google.protobuf.ByteString
        getMemoryOptimizerTargetNodeNameScopeBytes() {
      java.lang.Object ref = memoryOptimizerTargetNodeNameScope_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        memoryOptimizerTargetNodeNameScope_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     * <pre>
     * A node name scope for node names which are valid outputs of recomputations.
     * Inputs to nodes that match this scope may be recomputed (subject either to
     * manual annotation of those input nodes or to manual annotation and
     * heuristics depending on memory_optimization), but the nodes themselves will
     * not be recomputed. This matches any sub-scopes as well, meaning the scope
     * can appear not just as a top-level scope. For example, if the value is
     * "gradients/", the default, it will match node name "gradients/foo",
     * "foo/gradients/bar", but not "foo_gradients/"
     * </pre>
     *
     * <code>string memory_optimizer_target_node_name_scope = 6;</code>
     * @param value The memoryOptimizerTargetNodeNameScope to set.
     * @return This builder for chaining.
     */
    public Builder setMemoryOptimizerTargetNodeNameScope(
        java.lang.String value) {
      if (value == null) {
    throw new NullPointerException();
  }
  
      memoryOptimizerTargetNodeNameScope_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * A node name scope for node names which are valid outputs of recomputations.
     * Inputs to nodes that match this scope may be recomputed (subject either to
     * manual annotation of those input nodes or to manual annotation and
     * heuristics depending on memory_optimization), but the nodes themselves will
     * not be recomputed. This matches any sub-scopes as well, meaning the scope
     * can appear not just as a top-level scope. For example, if the value is
     * "gradients/", the default, it will match node name "gradients/foo",
     * "foo/gradients/bar", but not "foo_gradients/"
     * </pre>
     *
     * <code>string memory_optimizer_target_node_name_scope = 6;</code>
     * @return This builder for chaining.
     */
    public Builder clearMemoryOptimizerTargetNodeNameScope() {
      
      memoryOptimizerTargetNodeNameScope_ = getDefaultInstance().getMemoryOptimizerTargetNodeNameScope();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * A node name scope for node names which are valid outputs of recomputations.
     * Inputs to nodes that match this scope may be recomputed (subject either to
     * manual annotation of those input nodes or to manual annotation and
     * heuristics depending on memory_optimization), but the nodes themselves will
     * not be recomputed. This matches any sub-scopes as well, meaning the scope
     * can appear not just as a top-level scope. For example, if the value is
     * "gradients/", the default, it will match node name "gradients/foo",
     * "foo/gradients/bar", but not "foo_gradients/"
     * </pre>
     *
     * <code>string memory_optimizer_target_node_name_scope = 6;</code>
     * @param value The bytes for memoryOptimizerTargetNodeNameScope to set.
     * @return This builder for chaining.
     */
    public Builder setMemoryOptimizerTargetNodeNameScopeBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
      
      memoryOptimizerTargetNodeNameScope_ = value;
      onChanged();
      return this;
    }

    private long metaOptimizerTimeoutMs_ ;
    /**
     * <pre>
     * Maximum number of milliseconds to spend optimizing a single graph before
     * timing out. If less than or equal to 0 (default value) the optimizer will
     * never time out.
     * </pre>
     *
     * <code>int64 meta_optimizer_timeout_ms = 20;</code>
     * @return The metaOptimizerTimeoutMs.
     */
    @java.lang.Override
    public long getMetaOptimizerTimeoutMs() {
      return metaOptimizerTimeoutMs_;
    }
    /**
     * <pre>
     * Maximum number of milliseconds to spend optimizing a single graph before
     * timing out. If less than or equal to 0 (default value) the optimizer will
     * never time out.
     * </pre>
     *
     * <code>int64 meta_optimizer_timeout_ms = 20;</code>
     * @param value The metaOptimizerTimeoutMs to set.
     * @return This builder for chaining.
     */
    public Builder setMetaOptimizerTimeoutMs(long value) {
      
      metaOptimizerTimeoutMs_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * Maximum number of milliseconds to spend optimizing a single graph before
     * timing out. If less than or equal to 0 (default value) the optimizer will
     * never time out.
     * </pre>
     *
     * <code>int64 meta_optimizer_timeout_ms = 20;</code>
     * @return This builder for chaining.
     */
    public Builder clearMetaOptimizerTimeoutMs() {
      
      metaOptimizerTimeoutMs_ = 0L;
      onChanged();
      return this;
    }

    private org.tensorflow.proto.framework.AutoParallelOptions autoParallel_;
    private com.google.protobuf.SingleFieldBuilderV3<
        org.tensorflow.proto.framework.AutoParallelOptions, org.tensorflow.proto.framework.AutoParallelOptions.Builder, org.tensorflow.proto.framework.AutoParallelOptionsOrBuilder> autoParallelBuilder_;
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     * @return Whether the autoParallel field is set.
     */
    public boolean hasAutoParallel() {
      return autoParallelBuilder_ != null || autoParallel_ != null;
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     * @return The autoParallel.
     */
    public org.tensorflow.proto.framework.AutoParallelOptions getAutoParallel() {
      if (autoParallelBuilder_ == null) {
        return autoParallel_ == null ? org.tensorflow.proto.framework.AutoParallelOptions.getDefaultInstance() : autoParallel_;
      } else {
        return autoParallelBuilder_.getMessage();
      }
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public Builder setAutoParallel(org.tensorflow.proto.framework.AutoParallelOptions value) {
      if (autoParallelBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        autoParallel_ = value;
        onChanged();
      } else {
        autoParallelBuilder_.setMessage(value);
      }

      return this;
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public Builder setAutoParallel(
        org.tensorflow.proto.framework.AutoParallelOptions.Builder builderForValue) {
      if (autoParallelBuilder_ == null) {
        autoParallel_ = builderForValue.build();
        onChanged();
      } else {
        autoParallelBuilder_.setMessage(builderForValue.build());
      }

      return this;
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public Builder mergeAutoParallel(org.tensorflow.proto.framework.AutoParallelOptions value) {
      if (autoParallelBuilder_ == null) {
        if (autoParallel_ != null) {
          autoParallel_ =
            org.tensorflow.proto.framework.AutoParallelOptions.newBuilder(autoParallel_).mergeFrom(value).buildPartial();
        } else {
          autoParallel_ = value;
        }
        onChanged();
      } else {
        autoParallelBuilder_.mergeFrom(value);
      }

      return this;
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public Builder clearAutoParallel() {
      if (autoParallelBuilder_ == null) {
        autoParallel_ = null;
        onChanged();
      } else {
        autoParallel_ = null;
        autoParallelBuilder_ = null;
      }

      return this;
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public org.tensorflow.proto.framework.AutoParallelOptions.Builder getAutoParallelBuilder() {
      
      onChanged();
      return getAutoParallelFieldBuilder().getBuilder();
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    public org.tensorflow.proto.framework.AutoParallelOptionsOrBuilder getAutoParallelOrBuilder() {
      if (autoParallelBuilder_ != null) {
        return autoParallelBuilder_.getMessageOrBuilder();
      } else {
        return autoParallel_ == null ?
            org.tensorflow.proto.framework.AutoParallelOptions.getDefaultInstance() : autoParallel_;
      }
    }
    /**
     * <pre>
     * Configures AutoParallel optimization passes either through the
     * meta-optimizer or when manually specified through the optimizers field.
     * </pre>
     *
     * <code>.tensorflow.AutoParallelOptions auto_parallel = 5;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.tensorflow.proto.framework.AutoParallelOptions, org.tensorflow.proto.framework.AutoParallelOptions.Builder, org.tensorflow.proto.framework.AutoParallelOptionsOrBuilder> 
        getAutoParallelFieldBuilder() {
      if (autoParallelBuilder_ == null) {
        autoParallelBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.tensorflow.proto.framework.AutoParallelOptions, org.tensorflow.proto.framework.AutoParallelOptions.Builder, org.tensorflow.proto.framework.AutoParallelOptionsOrBuilder>(
                getAutoParallel(),
                getParentForChildren(),
                isClean());
        autoParallel_ = null;
      }
      return autoParallelBuilder_;
    }

    private boolean failOnOptimizerErrors_ ;
    /**
     * <pre>
     * If true, any optimization pass failing will cause the MetaOptimizer to
     * stop with an error. By default - or when set to false, failing passes are
     * skipped silently.
     * </pre>
     *
     * <code>bool fail_on_optimizer_errors = 21;</code>
     * @return The failOnOptimizerErrors.
     */
    @java.lang.Override
    public boolean getFailOnOptimizerErrors() {
      return failOnOptimizerErrors_;
    }
    /**
     * <pre>
     * If true, any optimization pass failing will cause the MetaOptimizer to
     * stop with an error. By default - or when set to false, failing passes are
     * skipped silently.
     * </pre>
     *
     * <code>bool fail_on_optimizer_errors = 21;</code>
     * @param value The failOnOptimizerErrors to set.
     * @return This builder for chaining.
     */
    public Builder setFailOnOptimizerErrors(boolean value) {
      
      failOnOptimizerErrors_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * If true, any optimization pass failing will cause the MetaOptimizer to
     * stop with an error. By default - or when set to false, failing passes are
     * skipped silently.
     * </pre>
     *
     * <code>bool fail_on_optimizer_errors = 21;</code>
     * @return This builder for chaining.
     */
    public Builder clearFailOnOptimizerErrors() {
      
      failOnOptimizerErrors_ = false;
      onChanged();
      return this;
    }

    private org.tensorflow.proto.framework.ScopedAllocatorOptions scopedAllocatorOpts_;
    private com.google.protobuf.SingleFieldBuilderV3<
        org.tensorflow.proto.framework.ScopedAllocatorOptions, org.tensorflow.proto.framework.ScopedAllocatorOptions.Builder, org.tensorflow.proto.framework.ScopedAllocatorOptionsOrBuilder> scopedAllocatorOptsBuilder_;
    /**
     * <code>.tensorflow.ScopedAllocatorOptions scoped_allocator_opts = 16;</code>
     * @return Whether the scopedAllocatorOpts field is set.
     */
    public boolean hasScopedAllocatorOpts() {
      return scopedAllocatorOptsBuilder_ != null || scopedAllocatorOpts_ != null;
    }
    /**
     * <code>.tensorflow.ScopedAllocatorOptions scoped_allocator_opts = 16;</code>
     * @return The scopedAllocatorOpts.
     */
    public org.tensorflow.proto.framework.ScopedAllocatorOptions getScopedAllocatorOpts() {
      if (scopedAllocatorOptsBuilder_ == null) {
        return scopedAllocatorOpts_ == null ? org.tensorflow.proto.framework.ScopedAllocatorOptions.getDefaultInstance() : scopedAllocatorOpts_;
      } else {
        return scopedAllocatorOptsBuilder_.getMessage();
      }
    }
    /**
     * <code>.tensorflow.ScopedAllocatorOptions scoped_allocator_opts = 16;</code>
     */
    public Builder setScopedAllocatorOpts(org.tensorflow.proto.framework.ScopedAllocatorOptions value) {
      if (scopedAllocatorOptsBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        scopedAllocatorOpts_ = value;
        onChanged();
      } else {
        scopedAllocatorOptsBuilder_.setMessage(value);
      }

      return this;
    }
    /**
     * <code>.tensorflow.ScopedAllocatorOptions scoped_allocator_opts = 16;</code>
     */
    public Builder setScopedAllocatorOpts(
        org.tensorflow.proto.framework.ScopedAllocatorOptions.Builder builderForValue) {
      if (scopedAllocatorOptsBuilder_ == null) {
        scopedAllocatorOpts_ = builderForValue.build();
        onChanged();
      } else {
        scopedAllocatorOptsBuilder_.setMessage(builderForValue.build());
      }

      return this;
    }
    /**
     * <code>.tensorflow.ScopedAllocatorOptions scoped_allocator_opts = 16;</code>
     */
    public Builder mergeScopedAllocatorOpts(org.tensorflow.proto.framework.ScopedAllocatorOptions value) {
      if (scopedAllocatorOptsBuilder_ == null) {
        if (scopedAllocatorOpts_ != null) {
          scopedAllocatorOpts_ =
            org.tensorflow.proto.framework.ScopedAllocatorOptions.newBuilder(scopedAllocatorOpts_).mergeFrom(value).buildPartial();
        } else {
          scopedAllocatorOpts_ = value;
        }
        onChanged();
      } else {
        scopedAllocatorOptsBuilder_.mergeFrom(value);
      }

      return this;
    }
    /**
     * <code>.tensorflow.ScopedAllocatorOptions scoped_allocator_opts = 16;</code>
     */
    public Builder clearScopedAllocatorOpts() {
      if (scopedAllocatorOptsBuilder_ == null) {
        scopedAllocatorOpts_ = null;
        onChanged();
      } else {
        scopedAllocatorOpts_ = null;
        scopedAllocatorOptsBuilder_ = null;
      }

      return this;
    }
    /**
     * <code>.tensorflow.ScopedAllocatorOptions scoped_allocator_opts = 16;</code>
     */
    public org.tensorflow.proto.framework.ScopedAllocatorOptions.Builder getScopedAllocatorOptsBuilder() {
      
      onChanged();
      return getScopedAllocatorOptsFieldBuilder().getBuilder();
    }
    /**
     * <code>.tensorflow.ScopedAllocatorOptions scoped_allocator_opts = 16;</code>
     */
    public org.tensorflow.proto.framework.ScopedAllocatorOptionsOrBuilder getScopedAllocatorOptsOrBuilder() {
      if (scopedAllocatorOptsBuilder_ != null) {
        return scopedAllocatorOptsBuilder_.getMessageOrBuilder();
      } else {
        return scopedAllocatorOpts_ == null ?
            org.tensorflow.proto.framework.ScopedAllocatorOptions.getDefaultInstance() : scopedAllocatorOpts_;
      }
    }
    /**
     * <code>.tensorflow.ScopedAllocatorOptions scoped_allocator_opts = 16;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.tensorflow.proto.framework.ScopedAllocatorOptions, org.tensorflow.proto.framework.ScopedAllocatorOptions.Builder, org.tensorflow.proto.framework.ScopedAllocatorOptionsOrBuilder> 
        getScopedAllocatorOptsFieldBuilder() {
      if (scopedAllocatorOptsBuilder_ == null) {
        scopedAllocatorOptsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.tensorflow.proto.framework.ScopedAllocatorOptions, org.tensorflow.proto.framework.ScopedAllocatorOptions.Builder, org.tensorflow.proto.framework.ScopedAllocatorOptionsOrBuilder>(
                getScopedAllocatorOpts(),
                getParentForChildren(),
                isClean());
        scopedAllocatorOpts_ = null;
      }
      return scopedAllocatorOptsBuilder_;
    }

    private com.google.protobuf.LazyStringList optimizers_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    private void ensureOptimizersIsMutable() {
      if (!((bitField0_ & 0x00000001) != 0)) {
        optimizers_ = new com.google.protobuf.LazyStringArrayList(optimizers_);
        bitField0_ |= 0x00000001;
       }
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * Custom optimizers (see custom_optimizers) that are not part of this
     * schedule will be run after - in the order that they were specified.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     * @return A list containing the optimizers.
     */
    public com.google.protobuf.ProtocolStringList
        getOptimizersList() {
      return optimizers_.getUnmodifiableView();
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * Custom optimizers (see custom_optimizers) that are not part of this
     * schedule will be run after - in the order that they were specified.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     * @return The count of optimizers.
     */
    public int getOptimizersCount() {
      return optimizers_.size();
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * Custom optimizers (see custom_optimizers) that are not part of this
     * schedule will be run after - in the order that they were specified.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     * @param index The index of the element to return.
     * @return The optimizers at the given index.
     */
    public java.lang.String getOptimizers(int index) {
      return optimizers_.get(index);
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * Custom optimizers (see custom_optimizers) that are not part of this
     * schedule will be run after - in the order that they were specified.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     * @param index The index of the value to return.
     * @return The bytes of the optimizers at the given index.
     */
    public com.google.protobuf.ByteString
        getOptimizersBytes(int index) {
      return optimizers_.getByteString(index);
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * Custom optimizers (see custom_optimizers) that are not part of this
     * schedule will be run after - in the order that they were specified.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     * @param index The index to set the value at.
     * @param value The optimizers to set.
     * @return This builder for chaining.
     */
    public Builder setOptimizers(
        int index, java.lang.String value) {
      if (value == null) {
    throw new NullPointerException();
  }
  ensureOptimizersIsMutable();
      optimizers_.set(index, value);
      onChanged();
      return this;
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * Custom optimizers (see custom_optimizers) that are not part of this
     * schedule will be run after - in the order that they were specified.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     * @param value The optimizers to add.
     * @return This builder for chaining.
     */
    public Builder addOptimizers(
        java.lang.String value) {
      if (value == null) {
    throw new NullPointerException();
  }
  ensureOptimizersIsMutable();
      optimizers_.add(value);
      onChanged();
      return this;
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * Custom optimizers (see custom_optimizers) that are not part of this
     * schedule will be run after - in the order that they were specified.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     * @param values The optimizers to add.
     * @return This builder for chaining.
     */
    public Builder addAllOptimizers(
        java.lang.Iterable<java.lang.String> values) {
      ensureOptimizersIsMutable();
      com.google.protobuf.AbstractMessageLite.Builder.addAll(
          values, optimizers_);
      onChanged();
      return this;
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * Custom optimizers (see custom_optimizers) that are not part of this
     * schedule will be run after - in the order that they were specified.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     * @return This builder for chaining.
     */
    public Builder clearOptimizers() {
      optimizers_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      bitField0_ = (bitField0_ & ~0x00000001);
      onChanged();
      return this;
    }
    /**
     * <pre>
     * If non-empty, will use this as an alternative way to specify a list of
     * optimizations to turn on and the order of the optimizations (replacing the
     * meta-optimizer).
     * Of the RewriterConfig options, only the AutoParallel configuration options
     * (the auto_parallel field) apply to manually requested optimization passes
     * ("autoparallel"). Memory optimization passes ("memory") invoked here are
     * not configurable (in contrast to memory optimization passes through the
     * meta-optimizer) and act only on manual op annotations.
     * Custom optimizers (see custom_optimizers) that are not part of this
     * schedule will be run after - in the order that they were specified.
     * </pre>
     *
     * <code>repeated string optimizers = 100;</code>
     * @param value The bytes of the optimizers to add.
     * @return This builder for chaining.
     */
    public Builder addOptimizersBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
      ensureOptimizersIsMutable();
      optimizers_.add(value);
      onChanged();
      return this;
    }

    private java.util.List<org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer> customOptimizers_ =
      java.util.Collections.emptyList();
    private void ensureCustomOptimizersIsMutable() {
      if (!((bitField0_ & 0x00000002) != 0)) {
        customOptimizers_ = new java.util.ArrayList<org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer>(customOptimizers_);
        bitField0_ |= 0x00000002;
       }
    }

    private com.google.protobuf.RepeatedFieldBuilderV3<
        org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer, org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.Builder, org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizerOrBuilder> customOptimizersBuilder_;

    /**
     * <pre>
     * list of CustomGraphOptimizers to apply.
     * </pre>
     *
     * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
     */
    public java.util.List<org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer> getCustomOptimizersList() {
      if (customOptimizersBuilder_ == null) {
        return java.util.Collections.unmodifiableList(customOptimizers_);
      } else {
        return customOptimizersBuilder_.getMessageList();
      }
    }
    /**
     * <pre>
     * list of CustomGraphOptimizers to apply.
     * </pre>
     *
     * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
     */
    public int getCustomOptimizersCount() {
      if (customOptimizersBuilder_ == null) {
        return customOptimizers_.size();
      } else {
        return customOptimizersBuilder_.getCount();
      }
    }
    /**
     * <pre>
     * list of CustomGraphOptimizers to apply.
     * </pre>
     *
     * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
     */
    public org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer getCustomOptimizers(int index) {
      if (customOptimizersBuilder_ == null) {
        return customOptimizers_.get(index);
      } else {
        return customOptimizersBuilder_.getMessage(index);
      }
    }
    /**
     * <pre>
     * list of CustomGraphOptimizers to apply.
     * </pre>
     *
     * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
     */
    public Builder setCustomOptimizers(
        int index, org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer value) {
      if (customOptimizersBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureCustomOptimizersIsMutable();
        customOptimizers_.set(index, value);
        onChanged();
      } else {
        customOptimizersBuilder_.setMessage(index, value);
      }
      return this;
    }
    /**
     * <pre>
     * list of CustomGraphOptimizers to apply.
     * </pre>
     *
     * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
     */
    public Builder setCustomOptimizers(
        int index, org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.Builder builderForValue) {
      if (customOptimizersBuilder_ == null) {
        ensureCustomOptimizersIsMutable();
        customOptimizers_.set(index, builderForValue.build());
        onChanged();
      } else {
        customOptimizersBuilder_.setMessage(index, builderForValue.build());
      }
      return this;
    }
    /**
     * <pre>
     * list of CustomGraphOptimizers to apply.
     * </pre>
     *
     * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
     */
    public Builder addCustomOptimizers(org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer value) {
      if (customOptimizersBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureCustomOptimizersIsMutable();
        customOptimizers_.add(value);
        onChanged();
      } else {
        customOptimizersBuilder_.addMessage(value);
      }
      return this;
    }
    /**
     * <pre>
     * list of CustomGraphOptimizers to apply.
     * </pre>
     *
     * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
     */
    public Builder addCustomOptimizers(
        int index, org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer value) {
      if (customOptimizersBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureCustomOptimizersIsMutable();
        customOptimizers_.add(index, value);
        onChanged();
      } else {
        customOptimizersBuilder_.addMessage(index, value);
      }
      return this;
    }
    /**
     * <pre>
     * list of CustomGraphOptimizers to apply.
     * </pre>
     *
     * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
     */
    public Builder addCustomOptimizers(
        org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.Builder builderForValue) {
      if (customOptimizersBuilder_ == null) {
        ensureCustomOptimizersIsMutable();
        customOptimizers_.add(builderForValue.build());
        onChanged();
      } else {
        customOptimizersBuilder_.addMessage(builderForValue.build());
      }
      return this;
    }
    /**
     * <pre>
     * list of CustomGraphOptimizers to apply.
     * </pre>
     *
     * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
     */
    public Builder addCustomOptimizers(
        int index, org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.Builder builderForValue) {
      if (customOptimizersBuilder_ == null) {
        ensureCustomOptimizersIsMutable();
        customOptimizers_.add(index, builderForValue.build());
        onChanged();
      } else {
        customOptimizersBuilder_.addMessage(index, builderForValue.build());
      }
      return this;
    }
    /**
     * <pre>
     * list of CustomGraphOptimizers to apply.
     * </pre>
     *
     * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
     */
    public Builder addAllCustomOptimizers(
        java.lang.Iterable<? extends org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer> values) {
      if (customOptimizersBuilder_ == null) {
        ensureCustomOptimizersIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, customOptimizers_);
        onChanged();
      } else {
        customOptimizersBuilder_.addAllMessages(values);
      }
      return this;
    }
    /**
     * <pre>
     * list of CustomGraphOptimizers to apply.
     * </pre>
     *
     * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
     */
    public Builder clearCustomOptimizers() {
      if (customOptimizersBuilder_ == null) {
        customOptimizers_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
      } else {
        customOptimizersBuilder_.clear();
      }
      return this;
    }
    /**
     * <pre>
     * list of CustomGraphOptimizers to apply.
     * </pre>
     *
     * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
     */
    public Builder removeCustomOptimizers(int index) {
      if (customOptimizersBuilder_ == null) {
        ensureCustomOptimizersIsMutable();
        customOptimizers_.remove(index);
        onChanged();
      } else {
        customOptimizersBuilder_.remove(index);
      }
      return this;
    }
    /**
     * <pre>
     * list of CustomGraphOptimizers to apply.
     * </pre>
     *
     * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
     */
    public org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.Builder getCustomOptimizersBuilder(
        int index) {
      return getCustomOptimizersFieldBuilder().getBuilder(index);
    }
    /**
     * <pre>
     * list of CustomGraphOptimizers to apply.
     * </pre>
     *
     * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
     */
    public org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizerOrBuilder getCustomOptimizersOrBuilder(
        int index) {
      if (customOptimizersBuilder_ == null) {
        return customOptimizers_.get(index);  } else {
        return customOptimizersBuilder_.getMessageOrBuilder(index);
      }
    }
    /**
     * <pre>
     * list of CustomGraphOptimizers to apply.
     * </pre>
     *
     * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
     */
    public java.util.List<? extends org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizerOrBuilder> 
         getCustomOptimizersOrBuilderList() {
      if (customOptimizersBuilder_ != null) {
        return customOptimizersBuilder_.getMessageOrBuilderList();
      } else {
        return java.util.Collections.unmodifiableList(customOptimizers_);
      }
    }
    /**
     * <pre>
     * list of CustomGraphOptimizers to apply.
     * </pre>
     *
     * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
     */
    public org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.Builder addCustomOptimizersBuilder() {
      return getCustomOptimizersFieldBuilder().addBuilder(
          org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.getDefaultInstance());
    }
    /**
     * <pre>
     * list of CustomGraphOptimizers to apply.
     * </pre>
     *
     * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
     */
    public org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.Builder addCustomOptimizersBuilder(
        int index) {
      return getCustomOptimizersFieldBuilder().addBuilder(
          index, org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.getDefaultInstance());
    }
    /**
     * <pre>
     * list of CustomGraphOptimizers to apply.
     * </pre>
     *
     * <code>repeated .tensorflow.RewriterConfig.CustomGraphOptimizer custom_optimizers = 200;</code>
     */
    public java.util.List<org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.Builder> 
         getCustomOptimizersBuilderList() {
      return getCustomOptimizersFieldBuilder().getBuilderList();
    }
    private com.google.protobuf.RepeatedFieldBuilderV3<
        org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer, org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.Builder, org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizerOrBuilder> 
        getCustomOptimizersFieldBuilder() {
      if (customOptimizersBuilder_ == null) {
        customOptimizersBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
            org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer, org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizer.Builder, org.tensorflow.proto.framework.RewriterConfig.CustomGraphOptimizerOrBuilder>(
                customOptimizers_,
                ((bitField0_ & 0x00000002) != 0),
                getParentForChildren(),
                isClean());
        customOptimizers_ = null;
      }
      return customOptimizersBuilder_;
    }

    private org.tensorflow.proto.framework.VerifierConfig interOptimizerVerifierConfig_;
    private com.google.protobuf.SingleFieldBuilderV3<
        org.tensorflow.proto.framework.VerifierConfig, org.tensorflow.proto.framework.VerifierConfig.Builder, org.tensorflow.proto.framework.VerifierConfigOrBuilder> interOptimizerVerifierConfigBuilder_;
    /**
     * <pre>
     * VerifierConfig specifying the verifiers to be run after every optimizer.
     * </pre>
     *
     * <code>.tensorflow.VerifierConfig inter_optimizer_verifier_config = 300;</code>
     * @return Whether the interOptimizerVerifierConfig field is set.
     */
    public boolean hasInterOptimizerVerifierConfig() {
      return interOptimizerVerifierConfigBuilder_ != null || interOptimizerVerifierConfig_ != null;
    }
    /**
     * <pre>
     * VerifierConfig specifying the verifiers to be run after every optimizer.
     * </pre>
     *
     * <code>.tensorflow.VerifierConfig inter_optimizer_verifier_config = 300;</code>
     * @return The interOptimizerVerifierConfig.
     */
    public org.tensorflow.proto.framework.VerifierConfig getInterOptimizerVerifierConfig() {
      if (interOptimizerVerifierConfigBuilder_ == null) {
        return interOptimizerVerifierConfig_ == null ? org.tensorflow.proto.framework.VerifierConfig.getDefaultInstance() : interOptimizerVerifierConfig_;
      } else {
        return interOptimizerVerifierConfigBuilder_.getMessage();
      }
    }
    /**
     * <pre>
     * VerifierConfig specifying the verifiers to be run after every optimizer.
     * </pre>
     *
     * <code>.tensorflow.VerifierConfig inter_optimizer_verifier_config = 300;</code>
     */
    public Builder setInterOptimizerVerifierConfig(org.tensorflow.proto.framework.VerifierConfig value) {
      if (interOptimizerVerifierConfigBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        interOptimizerVerifierConfig_ = value;
        onChanged();
      } else {
        interOptimizerVerifierConfigBuilder_.setMessage(value);
      }

      return this;
    }
    /**
     * <pre>
     * VerifierConfig specifying the verifiers to be run after every optimizer.
     * </pre>
     *
     * <code>.tensorflow.VerifierConfig inter_optimizer_verifier_config = 300;</code>
     */
    public Builder setInterOptimizerVerifierConfig(
        org.tensorflow.proto.framework.VerifierConfig.Builder builderForValue) {
      if (interOptimizerVerifierConfigBuilder_ == null) {
        interOptimizerVerifierConfig_ = builderForValue.build();
        onChanged();
      } else {
        interOptimizerVerifierConfigBuilder_.setMessage(builderForValue.build());
      }

      return this;
    }
    /**
     * <pre>
     * VerifierConfig specifying the verifiers to be run after every optimizer.
     * </pre>
     *
     * <code>.tensorflow.VerifierConfig inter_optimizer_verifier_config = 300;</code>
     */
    public Builder mergeInterOptimizerVerifierConfig(org.tensorflow.proto.framework.VerifierConfig value) {
      if (interOptimizerVerifierConfigBuilder_ == null) {
        if (interOptimizerVerifierConfig_ != null) {
          interOptimizerVerifierConfig_ =
            org.tensorflow.proto.framework.VerifierConfig.newBuilder(interOptimizerVerifierConfig_).mergeFrom(value).buildPartial();
        } else {
          interOptimizerVerifierConfig_ = value;
        }
        onChanged();
      } else {
        interOptimizerVerifierConfigBuilder_.mergeFrom(value);
      }

      return this;
    }
    /**
     * <pre>
     * VerifierConfig specifying the verifiers to be run after every optimizer.
     * </pre>
     *
     * <code>.tensorflow.VerifierConfig inter_optimizer_verifier_config = 300;</code>
     */
    public Builder clearInterOptimizerVerifierConfig() {
      if (interOptimizerVerifierConfigBuilder_ == null) {
        interOptimizerVerifierConfig_ = null;
        onChanged();
      } else {
        interOptimizerVerifierConfig_ = null;
        interOptimizerVerifierConfigBuilder_ = null;
      }

      return this;
    }
    /**
     * <pre>
     * VerifierConfig specifying the verifiers to be run after every optimizer.
     * </pre>
     *
     * <code>.tensorflow.VerifierConfig inter_optimizer_verifier_config = 300;</code>
     */
    public org.tensorflow.proto.framework.VerifierConfig.Builder getInterOptimizerVerifierConfigBuilder() {
      
      onChanged();
      return getInterOptimizerVerifierConfigFieldBuilder().getBuilder();
    }
    /**
     * <pre>
     * VerifierConfig specifying the verifiers to be run after every optimizer.
     * </pre>
     *
     * <code>.tensorflow.VerifierConfig inter_optimizer_verifier_config = 300;</code>
     */
    public org.tensorflow.proto.framework.VerifierConfigOrBuilder getInterOptimizerVerifierConfigOrBuilder() {
      if (interOptimizerVerifierConfigBuilder_ != null) {
        return interOptimizerVerifierConfigBuilder_.getMessageOrBuilder();
      } else {
        return interOptimizerVerifierConfig_ == null ?
            org.tensorflow.proto.framework.VerifierConfig.getDefaultInstance() : interOptimizerVerifierConfig_;
      }
    }
    /**
     * <pre>
     * VerifierConfig specifying the verifiers to be run after every optimizer.
     * </pre>
     *
     * <code>.tensorflow.VerifierConfig inter_optimizer_verifier_config = 300;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.tensorflow.proto.framework.VerifierConfig, org.tensorflow.proto.framework.VerifierConfig.Builder, org.tensorflow.proto.framework.VerifierConfigOrBuilder> 
        getInterOptimizerVerifierConfigFieldBuilder() {
      if (interOptimizerVerifierConfigBuilder_ == null) {
        interOptimizerVerifierConfigBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.tensorflow.proto.framework.VerifierConfig, org.tensorflow.proto.framework.VerifierConfig.Builder, org.tensorflow.proto.framework.VerifierConfigOrBuilder>(
                getInterOptimizerVerifierConfig(),
                getParentForChildren(),
                isClean());
        interOptimizerVerifierConfig_ = null;
      }
      return interOptimizerVerifierConfigBuilder_;
    }

    private org.tensorflow.proto.framework.VerifierConfig postOptimizationVerifierConfig_;
    private com.google.protobuf.SingleFieldBuilderV3<
        org.tensorflow.proto.framework.VerifierConfig, org.tensorflow.proto.framework.VerifierConfig.Builder, org.tensorflow.proto.framework.VerifierConfigOrBuilder> postOptimizationVerifierConfigBuilder_;
    /**
     * <pre>
     * VerifierConfig specifying the verifiers to be run at the end, after all
     * optimizers have run.
     * </pre>
     *
     * <code>.tensorflow.VerifierConfig post_optimization_verifier_config = 301;</code>
     * @return Whether the postOptimizationVerifierConfig field is set.
     */
    public boolean hasPostOptimizationVerifierConfig() {
      return postOptimizationVerifierConfigBuilder_ != null || postOptimizationVerifierConfig_ != null;
    }
    /**
     * <pre>
     * VerifierConfig specifying the verifiers to be run at the end, after all
     * optimizers have run.
     * </pre>
     *
     * <code>.tensorflow.VerifierConfig post_optimization_verifier_config = 301;</code>
     * @return The postOptimizationVerifierConfig.
     */
    public org.tensorflow.proto.framework.VerifierConfig getPostOptimizationVerifierConfig() {
      if (postOptimizationVerifierConfigBuilder_ == null) {
        return postOptimizationVerifierConfig_ == null ? org.tensorflow.proto.framework.VerifierConfig.getDefaultInstance() : postOptimizationVerifierConfig_;
      } else {
        return postOptimizationVerifierConfigBuilder_.getMessage();
      }
    }
    /**
     * <pre>
     * VerifierConfig specifying the verifiers to be run at the end, after all
     * optimizers have run.
     * </pre>
     *
     * <code>.tensorflow.VerifierConfig post_optimization_verifier_config = 301;</code>
     */
    public Builder setPostOptimizationVerifierConfig(org.tensorflow.proto.framework.VerifierConfig value) {
      if (postOptimizationVerifierConfigBuilder_ == null) {
        if (value == null) {
          throw new NullPointerException();
        }
        postOptimizationVerifierConfig_ = value;
        onChanged();
      } else {
        postOptimizationVerifierConfigBuilder_.setMessage(value);
      }

      return this;
    }
    /**
     * <pre>
     * VerifierConfig specifying the verifiers to be run at the end, after all
     * optimizers have run.
     * </pre>
     *
     * <code>.tensorflow.VerifierConfig post_optimization_verifier_config = 301;</code>
     */
    public Builder setPostOptimizationVerifierConfig(
        org.tensorflow.proto.framework.VerifierConfig.Builder builderForValue) {
      if (postOptimizationVerifierConfigBuilder_ == null) {
        postOptimizationVerifierConfig_ = builderForValue.build();
        onChanged();
      } else {
        postOptimizationVerifierConfigBuilder_.setMessage(builderForValue.build());
      }

      return this;
    }
    /**
     * <pre>
     * VerifierConfig specifying the verifiers to be run at the end, after all
     * optimizers have run.
     * </pre>
     *
     * <code>.tensorflow.VerifierConfig post_optimization_verifier_config = 301;</code>
     */
    public Builder mergePostOptimizationVerifierConfig(org.tensorflow.proto.framework.VerifierConfig value) {
      if (postOptimizationVerifierConfigBuilder_ == null) {
        if (postOptimizationVerifierConfig_ != null) {
          postOptimizationVerifierConfig_ =
            org.tensorflow.proto.framework.VerifierConfig.newBuilder(postOptimizationVerifierConfig_).mergeFrom(value).buildPartial();
        } else {
          postOptimizationVerifierConfig_ = value;
        }
        onChanged();
      } else {
        postOptimizationVerifierConfigBuilder_.mergeFrom(value);
      }

      return this;
    }
    /**
     * <pre>
     * VerifierConfig specifying the verifiers to be run at the end, after all
     * optimizers have run.
     * </pre>
     *
     * <code>.tensorflow.VerifierConfig post_optimization_verifier_config = 301;</code>
     */
    public Builder clearPostOptimizationVerifierConfig() {
      if (postOptimizationVerifierConfigBuilder_ == null) {
        postOptimizationVerifierConfig_ = null;
        onChanged();
      } else {
        postOptimizationVerifierConfig_ = null;
        postOptimizationVerifierConfigBuilder_ = null;
      }

      return this;
    }
    /**
     * <pre>
     * VerifierConfig specifying the verifiers to be run at the end, after all
     * optimizers have run.
     * </pre>
     *
     * <code>.tensorflow.VerifierConfig post_optimization_verifier_config = 301;</code>
     */
    public org.tensorflow.proto.framework.VerifierConfig.Builder getPostOptimizationVerifierConfigBuilder() {
      
      onChanged();
      return getPostOptimizationVerifierConfigFieldBuilder().getBuilder();
    }
    /**
     * <pre>
     * VerifierConfig specifying the verifiers to be run at the end, after all
     * optimizers have run.
     * </pre>
     *
     * <code>.tensorflow.VerifierConfig post_optimization_verifier_config = 301;</code>
     */
    public org.tensorflow.proto.framework.VerifierConfigOrBuilder getPostOptimizationVerifierConfigOrBuilder() {
      if (postOptimizationVerifierConfigBuilder_ != null) {
        return postOptimizationVerifierConfigBuilder_.getMessageOrBuilder();
      } else {
        return postOptimizationVerifierConfig_ == null ?
            org.tensorflow.proto.framework.VerifierConfig.getDefaultInstance() : postOptimizationVerifierConfig_;
      }
    }
    /**
     * <pre>
     * VerifierConfig specifying the verifiers to be run at the end, after all
     * optimizers have run.
     * </pre>
     *
     * <code>.tensorflow.VerifierConfig post_optimization_verifier_config = 301;</code>
     */
    private com.google.protobuf.SingleFieldBuilderV3<
        org.tensorflow.proto.framework.VerifierConfig, org.tensorflow.proto.framework.VerifierConfig.Builder, org.tensorflow.proto.framework.VerifierConfigOrBuilder> 
        getPostOptimizationVerifierConfigFieldBuilder() {
      if (postOptimizationVerifierConfigBuilder_ == null) {
        postOptimizationVerifierConfigBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
            org.tensorflow.proto.framework.VerifierConfig, org.tensorflow.proto.framework.VerifierConfig.Builder, org.tensorflow.proto.framework.VerifierConfigOrBuilder>(
                getPostOptimizationVerifierConfig(),
                getParentForChildren(),
                isClean());
        postOptimizationVerifierConfig_ = null;
      }
      return postOptimizationVerifierConfigBuilder_;
    }
    @java.lang.Override
    public final Builder setUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.setUnknownFields(unknownFields);
    }

    @java.lang.Override
    public final Builder mergeUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return super.mergeUnknownFields(unknownFields);
    }


    // @@protoc_insertion_point(builder_scope:tensorflow.RewriterConfig)
  }

  // @@protoc_insertion_point(class_scope:tensorflow.RewriterConfig)
  private static final org.tensorflow.proto.framework.RewriterConfig DEFAULT_INSTANCE;
  static {
    DEFAULT_INSTANCE = new org.tensorflow.proto.framework.RewriterConfig();
  }

  public static org.tensorflow.proto.framework.RewriterConfig getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static final com.google.protobuf.Parser<RewriterConfig>
      PARSER = new com.google.protobuf.AbstractParser<RewriterConfig>() {
    @java.lang.Override
    public RewriterConfig parsePartialFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      Builder builder = newBuilder();
      try {
        builder.mergeFrom(input, extensionRegistry);
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(builder.buildPartial());
      } catch (com.google.protobuf.UninitializedMessageException e) {
        throw e.asInvalidProtocolBufferException().setUnfinishedMessage(builder.buildPartial());
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(e)
            .setUnfinishedMessage(builder.buildPartial());
      }
      return builder.buildPartial();
    }
  };

  public static com.google.protobuf.Parser<RewriterConfig> parser() {
    return PARSER;
  }

  @java.lang.Override
  public com.google.protobuf.Parser<RewriterConfig> getParserForType() {
    return PARSER;
  }

  @java.lang.Override
  public org.tensorflow.proto.framework.RewriterConfig getDefaultInstanceForType() {
    return DEFAULT_INSTANCE;
  }

}

