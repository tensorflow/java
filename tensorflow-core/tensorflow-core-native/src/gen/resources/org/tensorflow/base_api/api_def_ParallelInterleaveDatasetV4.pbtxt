op {
  graph_op_name: "ParallelInterleaveDatasetV4"
  visibility: HIDDEN
  in_arg {
    name: "input_dataset"
    description: <<END
Dataset that produces a stream of arguments for the function `f`.
END
  }
  in_arg {
    name: "other_arguments"
    description: <<END
Additional arguments to pass to `f` beyond those produced by `input_dataset`.
Evaluated once when the dataset is instantiated.
END
  }
  in_arg {
    name: "cycle_length"
    description: <<END
Number of datasets (each created by applying `f` to the elements of
`input_dataset`) among which the `ParallelInterleaveDatasetV2` will cycle in a
round-robin fashion.
END
  }
  in_arg {
    name: "block_length"
    description: <<END
Number of elements at a time to produce from each interleaved invocation of a
dataset returned by `f`.
END
  }
  in_arg {
    name: "buffer_output_elements"
    description: <<END
The number of elements each iterator being interleaved should buffer (similar
to the `.prefetch()` transformation for each interleaved iterator).
END
  }
  in_arg {
    name: "prefetch_input_elements"
    description: <<END
Determines the number of iterators to prefetch, allowing buffers to warm up and
data to be pre-fetched without blocking the main thread.
END
  }
  in_arg {
    name: "num_parallel_calls"
    description: <<END
Determines the number of threads that should be used for fetching data from
input datasets in parallel. The Python API `tf.data.experimental.AUTOTUNE`
constant can be used to indicate that the level of parallelism should be autotuned.
END
  }
  attr {
    name: "f"
    description: <<END
A function mapping elements of `input_dataset`, concatenated with
`other_arguments`, to a Dataset variant that contains elements matching
`output_types` and `output_shapes`.
END
  }
  attr {
    name: "deterministic"
    description: <<END
A string indicating the op-level determinism to use. Deterministic controls
whether the interleave is allowed to return elements out of order if the next
element to be returned isn't available, but a later element is. Options are
"true", "false", and "default". "default" indicates that determinism should be
decided by the `experimental_deterministic` parameter of `tf.data.Options`.
END
  }
  attr {
    name: "Targuments"
    description: <<END
Types of the elements of `other_arguments`.
END
  }
  attr {
    name: "output_types"
  }
  attr {
    name: "output_shapes"
  }
  summary: "Creates a dataset that applies `f` to the outputs of `input_dataset`."
  description: <<END
The resulting dataset is similar to the `InterleaveDataset`, except that the
dataset will fetch records from the interleaved datasets in parallel.

The `tf.data` Python API creates instances of this op from
`Dataset.interleave()` when the `num_parallel_calls` parameter of that method
is set to any value other than `None`.

By default, the output of this dataset will be deterministic, which may result
in the dataset blocking if the next data item to be returned isn't available.
In order to avoid head-of-line blocking, one can either set the `deterministic`
attribute to "false", or leave it as "default" and set the
`experimental_deterministic` parameter of `tf.data.Options` to `False`.
This can improve performance at the expense of non-determinism.
END
}
